<?xml version="1.0" encoding="UTF-8"?>
<xml><records><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Benish, William A.</author></authors></contributors><titles><title>A Review of the Application of Information Theory to Clinical Diagnostic Testing</title><secondary-title>Entropy</secondary-title></titles><periodical><full-title>Entropy</full-title></periodical><pages>97</pages><volume>22</volume><number>1</number><issue>1</issue><keywords><keyword>entropy</keyword><keyword>information theory</keyword><keyword>multiple diagnostic tests</keyword><keyword>mutual information</keyword><keyword>relative entropy</keyword></keywords><dates><year>2020</year><pub-dates><date>2020/1</date></pub-dates></dates><isbn>1099-4300</isbn><electronic-resource-num>10.3390/e22010097</electronic-resource-num><abstract>The fundamental information theory functions of entropy, relative entropy, and mutual information are directly applicable to clinical diagnostic testing. This is a consequence of the fact that an individual’s disease state and diagnostic test result are random variables. In this paper, we review the application of information theory to the quantification of diagnostic uncertainty, diagnostic information, and diagnostic test performance. An advantage of information theory functions over more established test performance measures is that they can be used when multiple disease states are under consideration as well as when the diagnostic test can yield multiple or continuous results. Since more than one diagnostic test is often required to help determine a patient’s disease state, we also discuss the application of the theory to situations in which more than one diagnostic test is used. The total diagnostic information provided by two or more tests can be partitioned into meaningful components.</abstract><remote-database-name>www.mdpi.com</remote-database-name><language>en</language><urls><web-urls><url>https://www.mdpi.com/1099-4300/22/1/97</url></web-urls></urls><access-date>2024-03-04 16:17:05</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Cheung, I.</author><author>Campbell, L.</author><author>LeBel, E. P.</author><author>Ackerman, R. A.</author><author>Aykutoğlu, B.</author><author>Bahník, Š.</author><author>Bowen, J. D.</author><author>Bredow, C. A.</author><author>Bromberg, C.</author><author>Caprariello, P. A.</author><author>Carcedo, R. J.</author><author>Carson, K. J.</author><author>Cobb, R. J.</author><author>Collins, N. L.</author><author>Corretti, C. A.</author><author>DiDonato, T. E.</author><author>Ellithorpe, C.</author><author>Fernández-Rouco, N.</author><author>Fuglestad, P. T.</author><author>Goldberg, R. M.</author><author>Golom, F. D.</author><author>Gündoğdu-Aktürk, E.</author><author>Hoplock, L. B.</author><author>Houdek, P.</author><author>Kane, H. S.</author><author>Kim, J. S.</author><author>Kraus, S.</author><author>Leone, C. T.</author><author>Li, N. P.</author><author>Logan, J. M.</author><author>Millman, R. D.</author><author>Morry, M. M.</author><author>Pink, J. C.</author><author>Ritchey, T.</author><author>Root Luna, L. M.</author><author>Sinclair, H. C.</author><author>Stinson, D. A.</author><author>Sucharyna, T. A.</author><author>Tidwell, N. D.</author><author>Uysal, A.</author><author>Vranka, M.</author><author>Winczewski, L. A.</author><author>Yong, J. C.</author></authors></contributors><titles><title>Registered Replication Report: Study 1 From Finkel, Rusbult, Kumashiro, &amp; Hannon (2002)</title><secondary-title>Perspectives on Psychological Science</secondary-title><short-title>Registered Replication Report</short-title></titles><periodical><full-title>Perspectives on Psychological Science</full-title><abbr-1>Perspect Psychol Sci</abbr-1></periodical><pages>750-764</pages><volume>11</volume><number>5</number><issue>5</issue><dates><year>2016</year><pub-dates><date>2016-09-01</date></pub-dates></dates><isbn>1745-6916</isbn><electronic-resource-num>10.1177/1745691616664694</electronic-resource-num><abstract>Finkel, Rusbult, Kumashiro, and Hannon (2002, Study 1) demonstrated a causal link between subjective commitment to a relationship and how people responded to hypothetical betrayals of that relationship. Participants primed to think about their commitment to their partner (high commitment) reacted to the betrayals with reduced exit and neglect responses relative to those primed to think about their independence from their partner (low commitment). The priming manipulation did not affect constructive voice and loyalty responses. Although other studies have demonstrated a correlation between subjective commitment and responses to betrayal, this study provides the only experimental evidence that inducing changes to subjective commitment can causally affect forgiveness responses. This Registered Replication Report (RRR) meta-analytically combines the results of 16 new direct replications of the original study, all of which followed a standardized, vetted, and preregistered protocol. The results showed little effect of the priming manipulation on the forgiveness outcome measures, but it also did not observe an effect of priming on subjective commitment, so the manipulation did not work as it had in the original study. We discuss possible explanations for the discrepancy between the findings from this RRR and the original study.</abstract><remote-database-name>SAGE Journals</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1177/1745691616664694</url></web-urls></urls><access-date>2024-02-13 16:44:17</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Bouwmeester, S.</author><author>Verkoeijen, P. P. J. L.</author><author>Aczel, B.</author><author>Barbosa, F.</author><author>Bègue, L.</author><author>Brañas-Garza, P.</author><author>Chmura, T. G. H.</author><author>Cornelissen, G.</author><author>Døssing, F. S.</author><author>Espín, A. M.</author><author>Evans, A. M.</author><author>Ferreira-Santos, F.</author><author>Fiedler, S.</author><author>Flegr, J.</author><author>Ghaffari, M.</author><author>Glöckner, A.</author><author>Goeschl, T.</author><author>Guo, L.</author><author>Hauser, O. P.</author><author>Hernan-Gonzalez, R.</author><author>Herrero, A.</author><author>Horne, Z.</author><author>Houdek, P.</author><author>Johannesson, M.</author><author>Koppel, L.</author><author>Kujal, P.</author><author>Laine, T.</author><author>Lohse, J.</author><author>Martins, E. C.</author><author>Mauro, C.</author><author>Mischkowski, D.</author><author>Mukherjee, S.</author><author>Myrseth, K. O. R.</author><author>Navarro-Martínez, D.</author><author>Neal, T. M. S.</author><author>Novakova, J.</author><author>Pagà, R.</author><author>Paiva, T. O.</author><author>Palfi, B.</author><author>Piovesan, M.</author><author>Rahal, R.-M.</author><author>Salomon, E.</author><author>Srinivasan, N.</author><author>Srivastava, A.</author><author>Szaszi, B.</author><author>Szollosi, A.</author><author>Thor, K. Ø.</author><author>Tinghög, G.</author><author>Trueblood, J. S.</author><author>Van Bavel, J. J.</author><author>van ‘t Veer, A. E.</author><author>Västfjäll, D.</author><author>Warner, M.</author><author>Wengström, E.</author><author>Wills, J.</author><author>Wollbrant, C. E.</author></authors></contributors><titles><title>Registered Replication Report: Rand, Greene, and Nowak (2012)</title><secondary-title>Perspectives on Psychological Science</secondary-title><short-title>Registered Replication Report</short-title></titles><periodical><full-title>Perspectives on Psychological Science</full-title><abbr-1>Perspect Psychol Sci</abbr-1></periodical><pages>527-542</pages><volume>12</volume><number>3</number><issue>3</issue><dates><year>2017</year><pub-dates><date>2017-05-01</date></pub-dates></dates><isbn>1745-6916</isbn><electronic-resource-num>10.1177/1745691617693624</electronic-resource-num><abstract>In an anonymous 4-person economic game, participants contributed more money to a common project (i.e., cooperated) when required to decide quickly than when forced to delay their decision (Rand, Greene &amp; Nowak, 2012), a pattern consistent with the social heuristics hypothesis proposed by Rand and colleagues. The results of studies using time pressure have been mixed, with some replication attempts observing similar patterns (e.g., Rand et al., 2014) and others observing null effects (e.g., Tinghög et al., 2013; Verkoeijen &amp; Bouwmeester, 2014). This Registered Replication Report (RRR) assessed the size and variability of the effect of time pressure on cooperative decisions by combining 21 separate, preregistered replications of the critical conditions from Study 7 of the original article (Rand et al., 2012). The primary planned analysis used data from all participants who were randomly assigned to conditions and who met the protocol inclusion criteria (an intent-to-treat approach that included the 65.9% of participants in the time-pressure condition and 7.5% in the forced-delay condition who did not adhere to the time constraints), and we observed a difference in contributions of −0.37 percentage points compared with an 8.6 percentage point difference calculated from the original data. Analyzing the data as the original article did, including data only for participants who complied with the time constraints, the RRR observed a 10.37 percentage point difference in contributions compared with a 15.31 percentage point difference in the original study. In combination, the results of the intent-to-treat analysis and the compliant-only analysis are consistent with the presence of selection biases and the absence of a causal effect of time pressure on cooperation.</abstract><remote-database-name>SAGE Journals</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1177/1745691617693624</url></web-urls></urls><access-date>2024-02-13 16:42:40</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Hagger, Martin S.</author><author>Chatzisarantis, Nikos L. D.</author><author>Alberts, Hugo</author><author>Anggono, Calvin Octavianus</author><author>Batailler, Cédric</author><author>Birt, Angela R.</author><author>Brand, Ralf</author><author>Brandt, Mark J.</author><author>Brewer, Gene</author><author>Bruyneel, Sabrina</author><author>Calvillo, Dustin P.</author><author>Campbell, W. Keith</author><author>Cannon, Peter R.</author><author>Carlucci, Marianna</author><author>Carruth, Nicholas P.</author><author>Cheung, Tracy</author><author>Crowell, Adrienne</author><author>De Ridder, Denise T. D.</author><author>Dewitte, Siegfried</author><author>Elson, Malte</author><author>Evans, Jacqueline R.</author><author>Fay, Benjamin A.</author><author>Fennis, Bob M.</author><author>Finley, Anna</author><author>Francis, Zoë</author><author>Heise, Elke</author><author>Hoemann, Henrik</author><author>Inzlicht, Michael</author><author>Koole, Sander L.</author><author>Koppel, Lina</author><author>Kroese, Floor</author><author>Lange, Florian</author><author>Lau, Kevin</author><author>Lynch, Bridget P.</author><author>Martijn, Carolien</author><author>Merckelbach, Harald</author><author>Mills, Nicole V.</author><author>Michirev, Alexej</author><author>Miyake, Akira</author><author>Mosser, Alexandra E.</author><author>Muise, Megan</author><author>Muller, Dominique</author><author>Muzi, Milena</author><author>Nalis, Dario</author><author>Nurwanti, Ratri</author><author>Otgaar, Henry</author><author>Philipp, Michael C.</author><author>Primoceri, Pierpaolo</author><author>Rentzsch, Katrin</author><author>Ringos, Lara</author><author>Schlinkert, Caroline</author><author>Schmeichel, Brandon J.</author><author>Schoch, Sarah F.</author><author>Schrama, Michel</author><author>Schütz, Astrid</author><author>Stamos, Angelos</author><author>Tinghög, Gustav</author><author>Ullrich, Johannes</author><author>vanDellen, Michelle</author><author>Wimbarti, Supra</author><author>Wolff, Wanja</author><author>Yusainy, Cleoputri</author><author>Zerhouni, Oulmann</author><author>Zwienenberg, Maria</author></authors></contributors><titles><title>A Multilab Preregistered Replication of the Ego-Depletion Effect</title><secondary-title>Perspectives on Psychological Science: A Journal of the Association for Psychological Science</secondary-title></titles><periodical><full-title>Perspectives on Psychological Science: A Journal of the Association for Psychological Science</full-title><abbr-1>Perspect Psychol Sci</abbr-1></periodical><pages>546-573</pages><volume>11</volume><number>4</number><issue>4</issue><keywords><keyword>Adult</keyword><keyword>Humans</keyword><keyword>Meta-Analysis as Topic</keyword><keyword>Reproducibility of Results</keyword><keyword>Research Design</keyword><keyword>Self-Control</keyword><keyword>Task Performance and Analysis</keyword><keyword>Young Adult</keyword><keyword>energy model</keyword><keyword>meta-analysis</keyword><keyword>resource depletion</keyword><keyword>self-regulation</keyword><keyword>strength model</keyword></keywords><dates><year>2016</year><pub-dates><date>2016-07</date></pub-dates></dates><isbn>1745-6924</isbn><electronic-resource-num>10.1177/1745691616652873</electronic-resource-num><abstract>Good self-control has been linked to adaptive outcomes such as better health, cohesive personal relationships, success in the workplace and at school, and less susceptibility to crime and addictions. In contrast, self-control failure is linked to maladaptive outcomes. Understanding the mechanisms by which self-control predicts behavior may assist in promoting better regulation and outcomes. A popular approach to understanding self-control is the strength or resource depletion model. Self-control is conceptualized as a limited resource that becomes depleted after a period of exertion resulting in self-control failure. The model has typically been tested using a sequential-task experimental paradigm, in which people completing an initial self-control task have reduced self-control capacity and poorer performance on a subsequent task, a state known as ego depletion Although a meta-analysis of ego-depletion experiments found a medium-sized effect, subsequent meta-analyses have questioned the size and existence of the effect and identified instances of possible bias. The analyses served as a catalyst for the current Registered Replication Report of the ego-depletion effect. Multiple laboratories (k = 23, total N = 2,141) conducted replications of a standardized ego-depletion protocol based on a sequential-task paradigm by Sripada et al. Meta-analysis of the studies revealed that the size of the ego-depletion effect was small with 95% confidence intervals (CIs) that encompassed zero (d = 0.04, 95% CI [-0.07, 0.15]. We discuss implications of the findings for the ego-depletion effect and the resource depletion model of self-control.</abstract><remote-database-name>PubMed</remote-database-name><language>eng</language></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Wagenmakers, E.-J.</author><author>Beek, T.</author><author>Dijkhoff, L.</author><author>Gronau, Q. F.</author><author>Acosta, A.</author><author>Adams, R. B.</author><author>Albohn, D. N.</author><author>Allard, E. S.</author><author>Benning, S. D.</author><author>Blouin-Hudon, E.-M.</author><author>Bulnes, L. C.</author><author>Caldwell, T. L.</author><author>Calin-Jageman, R. J.</author><author>Capaldi, C. A.</author><author>Carfagno, N. S.</author><author>Chasten, K. T.</author><author>Cleeremans, A.</author><author>Connell, L.</author><author>DeCicco, J. M.</author><author>Dijkstra, K.</author><author>Fischer, A. H.</author><author>Foroni, F.</author><author>Hess, U.</author><author>Holmes, K. J.</author><author>Jones, J. L. H.</author><author>Klein, O.</author><author>Koch, C.</author><author>Korb, S.</author><author>Lewinski, P.</author><author>Liao, J. D.</author><author>Lund, S.</author><author>Lupianez, J.</author><author>Lynott, D.</author><author>Nance, C. N.</author><author>Oosterwijk, S.</author><author>Ozdoğru, A. A.</author><author>Pacheco-Unguetti, A. P.</author><author>Pearson, B.</author><author>Powis, C.</author><author>Riding, S.</author><author>Roberts, T.-A.</author><author>Rumiati, R. I.</author><author>Senden, M.</author><author>Shea-Shumsky, N. B.</author><author>Sobocko, K.</author><author>Soto, J. A.</author><author>Steiner, T. G.</author><author>Talarico, J. M.</author><author>van Allen, Z. M.</author><author>Vandekerckhove, M.</author><author>Wainwright, B.</author><author>Wayand, J. F.</author><author>Zeelenberg, R.</author><author>Zetzer, E. E.</author><author>Zwaan, R. A.</author></authors></contributors><titles><title>Registered Replication Report: Strack, Martin, &amp; Stepper (1988)</title><secondary-title>Perspectives on Psychological Science</secondary-title><short-title>Registered Replication Report</short-title></titles><periodical><full-title>Perspectives on Psychological Science</full-title><abbr-1>Perspect Psychol Sci</abbr-1></periodical><pages>917-928</pages><volume>11</volume><number>6</number><issue>6</issue><dates><year>2016</year><pub-dates><date>2016-11-01</date></pub-dates></dates><isbn>1745-6916</isbn><electronic-resource-num>10.1177/1745691616674458</electronic-resource-num><abstract>According to the facial feedback hypothesis, people’s affective responses can be influenced by their own facial expression (e.g., smiling, pouting), even when their expression did not result from their emotional experiences. For example, Strack, Martin, and Stepper (1988) instructed participants to rate the funniness of cartoons using a pen that they held in their mouth. In line with the facial feedback hypothesis, when participants held the pen with their teeth (inducing a “smile”), they rated the cartoons as funnier than when they held the pen with their lips (inducing a “pout”). This seminal study of the facial feedback hypothesis has not been replicated directly. This Registered Replication Report describes the results of 17 independent direct replications of Study 1 from Strack et al. (1988), all of which followed the same vetted protocol. A meta-analysis of these studies examined the difference in funniness ratings between the “smile” and “pout” conditions. The original Strack et al. (1988) study reported a rating difference of 0.82 units on a 10-point Likert scale. Our meta-analysis revealed a rating difference of 0.03 units with a 95% confidence interval ranging from −0.11 to 0.16.</abstract><remote-database-name>SAGE Journals</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1177/1745691616674458</url></web-urls></urls><access-date>2024-02-13 16:37:40</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Page, Matthew J.</author><author>Moher, David</author><author>Fidler, Fiona M.</author><author>Higgins, Julian P. T.</author><author>Brennan, Sue E.</author><author>Haddaway, Neal R.</author><author>Hamilton, Daniel G.</author><author>Kanukula, Raju</author><author>Karunananthan, Sathya</author><author>Maxwell, Lara J.</author><author>McDonald, Steve</author><author>Nakagawa, Shinichi</author><author>Nunan, David</author><author>Tugwell, Peter</author><author>Welch, Vivian A.</author><author>McKenzie, Joanne E.</author></authors></contributors><titles><title>The REPRISE project: protocol for an evaluation of REProducibility and Replicability In Syntheses of Evidence</title><secondary-title>Systematic Reviews</secondary-title><short-title>The REPRISE project</short-title></titles><periodical><full-title>Systematic Reviews</full-title><abbr-1>Systematic Reviews</abbr-1></periodical><pages>112</pages><volume>10</volume><number>1</number><issue>1</issue><keywords><keyword>Meta-analysis</keyword><keyword>Methodology</keyword><keyword>Quality</keyword><keyword>Replication</keyword><keyword>Reproducibility of Results</keyword><keyword>Systematic reviews</keyword><keyword>Transparency</keyword></keywords><dates><year>2021</year><pub-dates><date>2021-04-16</date></pub-dates></dates><isbn>2046-4053</isbn><electronic-resource-num>10.1186/s13643-021-01670-0</electronic-resource-num><abstract>Investigations of transparency, reproducibility and replicability in science have been directed largely at individual studies. It is just as critical to explore these issues in syntheses of studies, such as systematic reviews, given their influence on decision-making and future research. We aim to explore various aspects relating to the transparency, reproducibility and replicability of several components of systematic reviews with meta-analysis of the effects of health, social, behavioural and educational interventions.</abstract><remote-database-name>BioMed Central</remote-database-name><urls><web-urls><url>https://doi.org/10.1186/s13643-021-01670-0</url></web-urls></urls><access-date>2024-02-13 15:47:39</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Low, Jeffrey</author><author>Ross, Joseph S.</author><author>Ritchie, Jessica D.</author><author>Gross, Cary P.</author><author>Lehman, Richard</author><author>Lin, Haiqun</author><author>Fu, Rongwei</author><author>Stewart, Lesley A.</author><author>Krumholz, Harlan M.</author></authors></contributors><titles><title>Comparison of two independent systematic reviews of trials of recombinant human bone morphogenetic protein-2 (rhBMP-2): the Yale Open Data Access Medtronic Project</title><secondary-title>Systematic Reviews</secondary-title><short-title>Comparison of two independent systematic reviews of trials of recombinant human bone morphogenetic protein-2 (rhBMP-2)</short-title></titles><periodical><full-title>Systematic Reviews</full-title><abbr-1>Systematic Reviews</abbr-1></periodical><pages>28</pages><volume>6</volume><number>1</number><issue>1</issue><keywords><keyword>Data interpretation</keyword><keyword>Data sharing</keyword><keyword>Meta-analysis</keyword><keyword>Systematic review</keyword></keywords><dates><year>2017</year><pub-dates><date>2017-02-15</date></pub-dates></dates><isbn>2046-4053</isbn><electronic-resource-num>10.1186/s13643-017-0422-x</electronic-resource-num><abstract>It is uncertain whether the replication of systematic reviews, particularly those with the same objectives and resources, would employ similar methods and/or arrive at identical findings. We compared the results and conclusions of two concurrent systematic reviews undertaken by two independent research teams provided with the same objectives, resources, and individual participant-level data.</abstract><remote-database-name>BioMed Central</remote-database-name><urls><web-urls><url>https://doi.org/10.1186/s13643-017-0422-x</url></web-urls></urls><access-date>2024-02-13 15:45:56</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Veronese, Mattia</author><author>Rizzo, Gaia</author><author>Belzunce, Martin</author><author>Schubert, Julia</author><author>Searle, Graham</author><author>Whittington, Alex</author><author>Mansur, Ayla</author><author>Dunn, Joel</author><author>Reader, Andrew</author><author>Gunn, Roger N.</author><author>Grand Challenge Participants#</author></authors></contributors><titles><title>Reproducibility of findings in modern PET neuroimaging: insight from the NRM2018 grand challenge</title><secondary-title>Journal of Cerebral Blood Flow and Metabolism: Official Journal of the International Society of Cerebral Blood Flow and Metabolism</secondary-title><short-title>Reproducibility of findings in modern PET neuroimaging</short-title></titles><periodical><full-title>Journal of Cerebral Blood Flow and Metabolism: Official Journal of the International Society of Cerebral Blood Flow and Metabolism</full-title><abbr-1>J Cereb Blood Flow Metab</abbr-1></periodical><pages>2778-2796</pages><volume>41</volume><number>10</number><issue>10</issue><keywords><keyword>Congresses as Topic</keyword><keyword>Female</keyword><keyword>History, 21st Century</keyword><keyword>Humans</keyword><keyword>Male</keyword><keyword>Neuroimaging</keyword><keyword>PET</keyword><keyword>Positron-Emission Tomography</keyword><keyword>Reproducibility of Results</keyword><keyword>data analysis</keyword><keyword>data sharing</keyword><keyword>reproducibility crisis</keyword><keyword>“NRM2018 PET Grand Challenge”</keyword></keywords><dates><year>2021</year><pub-dates><date>2021-10</date></pub-dates></dates><isbn>1559-7016</isbn><electronic-resource-num>10.1177/0271678X211015101</electronic-resource-num><abstract>The reproducibility of findings is a compelling methodological problem that the neuroimaging community is facing these days. The lack of standardized pipelines for image processing, quantification and statistics plays a major role in the variability and interpretation of results, even when the same data are analysed. This problem is well-known in MRI studies, where the indisputable value of the method has been complicated by a number of studies that produce discrepant results. However, any research domain with complex data and flexible analytical procedures can experience a similar lack of reproducibility. In this paper we investigate this issue for brain PET imaging. During the 2018 NeuroReceptor Mapping conference, the brain PET community was challenged with a computational contest involving a simulated neurotransmitter release experiment. Fourteen international teams analysed the same imaging dataset, for which the ground-truth was known. Despite a plurality of methods, the solutions were consistent across participants, although not identical. These results should create awareness that the increased sharing of PET data alone will only be one component of enhancing confidence in neuroimaging results and that it will be important to complement this with full details of the analysis pipelines and procedures that have been used to quantify data.</abstract><remote-database-name>PubMed</remote-database-name><language>eng</language></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>van Dongen, Noah N. N.</author><author>van Doorn, Johnny B.</author><author>Gronau, Quentin F.</author><author>van Ravenzwaaij, Don</author><author>Hoekstra, Rink</author><author>Haucke, Matthias N.</author><author>Lakens, Daniel</author><author>Hennig, Christian</author><author>Morey, Richard D.</author><author>Homer, Saskia</author><author>Gelman, Andrew</author><author>Sprenger, Jan</author><author>Wagenmakers, Eric-Jan</author></authors></contributors><titles><title>Multiple Perspectives on Inference for Two Simple Statistical Scenarios</title><secondary-title>The American Statistician</secondary-title></titles><periodical><full-title>The American Statistician</full-title></periodical><pages>328-339</pages><volume>73</volume><number>sup1</number><issue>sup1</issue><keywords><keyword>Frequentist or Bayesian</keyword><keyword>Multilab analysis</keyword><keyword>Statistical paradigms</keyword><keyword>Testing or estimation</keyword></keywords><dates><year>2019</year><pub-dates><date>2019-03-29</date></pub-dates></dates><isbn>0003-1305</isbn><electronic-resource-num>10.1080/00031305.2019.1565553</electronic-resource-num><abstract>When data analysts operate within different statistical frameworks (e.g., frequentist versus Bayesian, emphasis on estimation versus emphasis on testing), how does this impact the qualitative conclusions that are drawn for real data? To study this question empirically we selected from the literature two simple scenarios—involving a comparison of two proportions and a Pearson correlation—and asked four teams of statisticians to provide a concise analysis and a qualitative interpretation of the outcome. The results showed considerable overall agreement; nevertheless, this agreement did not appear to diminish the intensity of the subsequent debate over which statistical framework is more appropriate to address the questions at hand.</abstract><remote-database-name>Taylor and Francis+NEJM</remote-database-name><urls><web-urls><url>https://doi.org/10.1080/00031305.2019.1565553</url></web-urls></urls><access-date>2024-02-13 15:43:39</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Silberzahn, R.</author><author>Uhlmann, E. L.</author><author>Martin, D. P.</author><author>Anselmi, P.</author><author>Aust, F.</author><author>Awtrey, E.</author><author>Bahník, Š.</author><author>Bai, F.</author><author>Bannard, C.</author><author>Bonnier, E.</author><author>Carlsson, R.</author><author>Cheung, F.</author><author>Christensen, G.</author><author>Clay, R.</author><author>Craig, M. A.</author><author>Dalla Rosa, A.</author><author>Dam, L.</author><author>Evans, M. H.</author><author>Flores Cervantes, I.</author><author>Fong, N.</author><author>Gamez-Djokic, M.</author><author>Glenz, A.</author><author>Gordon-McKeon, S.</author><author>Heaton, T. J.</author><author>Hederos, K.</author><author>Heene, M.</author><author>Hofelich Mohr, A. J.</author><author>Högden, F.</author><author>Hui, K.</author><author>Johannesson, M.</author><author>Kalodimos, J.</author><author>Kaszubowski, E.</author><author>Kennedy, D. M.</author><author>Lei, R.</author><author>Lindsay, T. A.</author><author>Liverani, S.</author><author>Madan, C. R.</author><author>Molden, D.</author><author>Molleman, E.</author><author>Morey, R. D.</author><author>Mulder, L. B.</author><author>Nijstad, B. R.</author><author>Pope, N. G.</author><author>Pope, B.</author><author>Prenoveau, J. M.</author><author>Rink, F.</author><author>Robusto, E.</author><author>Roderique, H.</author><author>Sandberg, A.</author><author>Schlüter, E.</author><author>Schönbrodt, F. D.</author><author>Sherman, M. F.</author><author>Sommer, S. A.</author><author>Sotak, K.</author><author>Spain, S.</author><author>Spörlein, C.</author><author>Stafford, T.</author><author>Stefanutti, L.</author><author>Tauber, S.</author><author>Ullrich, J.</author><author>Vianello, M.</author><author>Wagenmakers, E.-J.</author><author>Witkowiak, M.</author><author>Yoon, S.</author><author>Nosek, B. A.</author></authors></contributors><titles><title>Many Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results</title><secondary-title>Advances in Methods and Practices in Psychological Science</secondary-title><short-title>Many Analysts, One Data Set</short-title></titles><periodical><full-title>Advances in Methods and Practices in Psychological Science</full-title></periodical><pages>337-356</pages><volume>1</volume><number>3</number><issue>3</issue><dates><year>2018</year><pub-dates><date>2018-09-01</date></pub-dates></dates><isbn>2515-2459</isbn><electronic-resource-num>10.1177/2515245917747646</electronic-resource-num><abstract>Twenty-nine teams involving 61 analysts used the same data set to address the same research question: whether soccer referees are more likely to give red cards to dark-skin-toned players than to light-skin-toned players. Analytic approaches varied widely across the teams, and the estimated effect sizes ranged from 0.89 to 2.93 (Mdn = 1.31) in odds-ratio units. Twenty teams (69%) found a statistically significant positive effect, and 9 teams (31%) did not observe a significant relationship. Overall, the 29 different analyses used 21 unique combinations of covariates. Neither analysts? prior beliefs about the effect of interest nor their level of expertise readily explained the variation in the outcomes of the analyses. Peer ratings of the quality of the analyses also did not account for the variability. These findings suggest that significant variation in the results of analyses of complex data may be difficult to avoid, even by experts with honest intentions. Crowdsourcing data analysis, a strategy in which numerous research teams are recruited to simultaneously investigate the same research question, makes transparent how defensible, yet subjective, analytic choices influence research results.</abstract><remote-database-name>SAGE Journals</remote-database-name><urls><web-urls><url>https://doi.org/10.1177/2515245917747646</url></web-urls></urls><access-date>2024-02-13 15:41:45</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Schweinsberg, Martin</author><author>Feldman, Michael</author><author>Staub, Nicola</author><author>van den Akker, Olmo R.</author><author>van Aert, Robbie C. M.</author><author>van Assen, Marcel A. L. M.</author><author>Liu, Yang</author><author>Althoff, Tim</author><author>Heer, Jeffrey</author><author>Kale, Alex</author><author>Mohamed, Zainab</author><author>Amireh, Hashem</author><author>Venkatesh Prasad, Vaishali</author><author>Bernstein, Abraham</author><author>Robinson, Emily</author><author>Snellman, Kaisa</author><author>Amy Sommer, S.</author><author>Otner, Sarah M. G.</author><author>Robinson, David</author><author>Madan, Nikhil</author><author>Silberzahn, Raphael</author><author>Goldstein, Pavel</author><author>Tierney, Warren</author><author>Murase, Toshio</author><author>Mandl, Benjamin</author><author>Viganola, Domenico</author><author>Strobl, Carolin</author><author>Schaumans, Catherine B. C.</author><author>Kelchtermans, Stijn</author><author>Naseeb, Chan</author><author>Mason Garrison, S.</author><author>Yarkoni, Tal</author><author>Richard Chan, C. S.</author><author>Adie, Prestone</author><author>Alaburda, Paulius</author><author>Albers, Casper</author><author>Alspaugh, Sara</author><author>Alstott, Jeff</author><author>Nelson, Andrew A.</author><author>Ariño de la Rubia, Eduardo</author><author>Arzi, Adbi</author><author>Bahník, Štěpán</author><author>Baik, Jason</author><author>Winther Balling, Laura</author><author>Banker, Sachin</author><author>AA Baranger, David</author><author>Barr, Dale J.</author><author>Barros-Rivera, Brenda</author><author>Bauer, Matt</author><author>Blaise, Enuh</author><author>Boelen, Lisa</author><author>Bohle Carbonell, Katerina</author><author>Briers, Robert A.</author><author>Burkhard, Oliver</author><author>Canela, Miguel-Angel</author><author>Castrillo, Laura</author><author>Catlett, Timothy</author><author>Chen, Olivia</author><author>Clark, Michael</author><author>Cohn, Brent</author><author>Coppock, Alex</author><author>Cugueró-Escofet, Natàlia</author><author>Curran, Paul G.</author><author>Cyrus-Lai, Wilson</author><author>Dai, David</author><author>Valentino Dalla Riva, Giulio</author><author>Danielsson, Henrik</author><author>Russo, Rosaria de F. S. M.</author><author>de Silva, Niko</author><author>Derungs, Curdin</author><author>Dondelinger, Frank</author><author>Duarte de Souza, Carolina</author><author>Tyson Dube, B.</author><author>Dubova, Marina</author><author>Mark Dunn, Ben</author><author>Adriaan Edelsbrunner, Peter</author><author>Finley, Sara</author><author>Fox, Nick</author><author>Gnambs, Timo</author><author>Gong, Yuanyuan</author><author>Grand, Erin</author><author>Greenawalt, Brandon</author><author>Han, Dan</author><author>Hanel, Paul H. P.</author><author>Hong, Antony B.</author><author>Hood, David</author><author>Hsueh, Justin</author><author>Huang, Lilian</author><author>Hui, Kent N.</author><author>Hultman, Keith A.</author><author>Javaid, Azka</author><author>Ji Jiang, Lily</author><author>Jong, Jonathan</author><author>Kamdar, Jash</author><author>Kane, David</author><author>Kappler, Gregor</author><author>Kaszubowski, Erikson</author><author>Kavanagh, Christopher M.</author><author>Khabsa, Madian</author><author>Kleinberg, Bennett</author><author>Kouros, Jens</author><author>Krause, Heather</author><author>Krypotos, Angelos-Miltiadis</author><author>Lavbič, Dejan</author><author>Ling Lee, Rui</author><author>Leffel, Timothy</author><author>Yang Lim, Wei</author><author>Liverani, Silvia</author><author>Loh, Bianca</author><author>Lønsmann, Dorte</author><author>Wei Low, Jia</author><author>Lu, Alton</author><author>MacDonald, Kyle</author><author>Madan, Christopher R.</author><author>Hjorth Madsen, Lasse</author><author>Maimone, Christina</author><author>Mangold, Alexandra</author><author>Marshall, Adrienne</author><author>Ester Matskewich, Helena</author><author>Mavon, Kimia</author><author>McLain, Katherine L.</author><author>McNamara, Amelia A.</author><author>McNeill, Mhairi</author><author>Mertens, Ulf</author><author>Miller, David</author><author>Moore, Ben</author><author>Moore, Andrew</author><author>Nantz, Eric</author><author>Nasrullah, Ziauddin</author><author>Nejkovic, Valentina</author><author>Nell, Colleen S</author><author>Arthur Nelson, Andrew</author><author>Nilsonne, Gustav</author><author>Nolan, Rory</author><author>O'Brien, Christopher E.</author><author>O'Neill, Patrick</author><author>O'Shea, Kieran</author><author>Olita, Toto</author><author>Otterbacher, Jahna</author><author>Palsetia, Diana</author><author>Pereira, Bianca</author><author>Pozdniakov, Ivan</author><author>Protzko, John</author><author>Reyt, Jean-Nicolas</author><author>Riddle, Travis</author><author>(Akmal) Ridhwan Omar Ali, Amal</author><author>Ropovik, Ivan</author><author>Rosenberg, Joshua M.</author><author>Rothen, Stephane</author><author>Schulte-Mecklenbeck, Michael</author><author>Sharma, Nirek</author><author>Shotwell, Gordon</author><author>Skarzynski, Martin</author><author>Stedden, William</author><author>Stodden, Victoria</author><author>Stoffel, Martin A.</author><author>Stoltzman, Scott</author><author>Subbaiah, Subashini</author><author>Tatman, Rachael</author><author>Thibodeau, Paul H.</author><author>Tomkins, Sabina</author><author>Valdivia, Ana</author><author>Druijff-van de Woestijne, Gerrieke B.</author><author>Viana, Laura</author><author>Villesèche, Florence</author><author>Duncan Wadsworth, W.</author><author>Wanders, Florian</author><author>Watts, Krista</author><author>Wells, Jason D</author><author>Whelpley, Christopher E.</author><author>Won, Andy</author><author>Wu, Lawrence</author><author>Yip, Arthur</author><author>Youngflesh, Casey</author><author>Yu, Ju-Chi</author><author>Zandian, Arash</author><author>Zhang, Leilei</author><author>Zibman, Chava</author><author>Luis Uhlmann, Eric</author></authors></contributors><titles><title>Same data, different conclusions: Radical dispersion in empirical results when independent analysts operationalize and test the same hypothesis</title><secondary-title>Organizational Behavior and Human Decision Processes</secondary-title><short-title>Same data, different conclusions</short-title></titles><periodical><full-title>Organizational Behavior and Human Decision Processes</full-title><abbr-1>Organizational Behavior and Human Decision Processes</abbr-1></periodical><pages>228-249</pages><volume>165</volume><keywords><keyword>Analysis-contingent results</keyword><keyword>Crowdsourcing data analysis</keyword><keyword>Research reliability</keyword><keyword>Researcher degrees of freedom</keyword><keyword>Scientific robustness</keyword><keyword>Scientific transparency</keyword></keywords><dates><year>2021</year><pub-dates><date>2021-07-01</date></pub-dates></dates><isbn>0749-5978</isbn><electronic-resource-num>10.1016/j.obhdp.2021.02.003</electronic-resource-num><abstract>In this crowdsourced initiative, independent analysts used the same dataset to test two hypotheses regarding the effects of scientists’ gender and professional status on verbosity during group meetings. Not only the analytic approach but also the operationalizations of key variables were left unconstrained and up to individual analysts. For instance, analysts could choose to operationalize status as job title, institutional ranking, citation counts, or some combination. To maximize transparency regarding the process by which analytic choices are made, the analysts used a platform we developed called DataExplained to justify both preferred and rejected analytic paths in real time. Analyses lacking sufficient detail, reproducible code, or with statistical errors were excluded, resulting in 29 analyses in the final sample. Researchers reported radically different analyses and dispersed empirical outcomes, in a number of cases obtaining significant effects in opposite directions for the same research question. A Boba multiverse analysis demonstrates that decisions about how to operationalize variables explain variability in outcomes above and beyond statistical choices (e.g., covariates). Subjective researcher decisions play a critical role in driving the reported empirical results, underscoring the need for open data, systematic robustness checks, and transparency regarding both analytic paths taken and not taken. Implications for organizations and leaders, whose decision making relies in part on scientific findings, consulting reports, and internal analyses by data scientists, are discussed.</abstract><remote-database-name>ScienceDirect</remote-database-name><urls><web-urls><url>https://www.sciencedirect.com/science/article/pii/S0749597821000200</url></web-urls></urls><access-date>2024-02-13 15:41:33</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Salganik, Matthew J.</author><author>Lundberg, Ian</author><author>Kindel, Alexander T.</author><author>Ahearn, Caitlin E.</author><author>Al-Ghoneim, Khaled</author><author>Almaatouq, Abdullah</author><author>Altschul, Drew M.</author><author>Brand, Jennie E.</author><author>Carnegie, Nicole Bohme</author><author>Compton, Ryan James</author><author>Datta, Debanjan</author><author>Davidson, Thomas</author><author>Filippova, Anna</author><author>Gilroy, Connor</author><author>Goode, Brian J.</author><author>Jahani, Eaman</author><author>Kashyap, Ridhi</author><author>Kirchner, Antje</author><author>McKay, Stephen</author><author>Morgan, Allison C.</author><author>Pentland, Alex</author><author>Polimis, Kivan</author><author>Raes, Louis</author><author>Rigobon, Daniel E.</author><author>Roberts, Claudia V.</author><author>Stanescu, Diana M.</author><author>Suhara, Yoshihiko</author><author>Usmani, Adaner</author><author>Wang, Erik H.</author><author>Adem, Muna</author><author>Alhajri, Abdulla</author><author>AlShebli, Bedoor</author><author>Amin, Redwane</author><author>Amos, Ryan B.</author><author>Argyle, Lisa P.</author><author>Baer-Bositis, Livia</author><author>Büchi, Moritz</author><author>Chung, Bo-Ryehn</author><author>Eggert, William</author><author>Faletto, Gregory</author><author>Fan, Zhilin</author><author>Freese, Jeremy</author><author>Gadgil, Tejomay</author><author>Gagné, Josh</author><author>Gao, Yue</author><author>Halpern-Manners, Andrew</author><author>Hashim, Sonia P.</author><author>Hausen, Sonia</author><author>He, Guanhua</author><author>Higuera, Kimberly</author><author>Hogan, Bernie</author><author>Horwitz, Ilana M.</author><author>Hummel, Lisa M.</author><author>Jain, Naman</author><author>Jin, Kun</author><author>Jurgens, David</author><author>Kaminski, Patrick</author><author>Karapetyan, Areg</author><author>Kim, E. H.</author><author>Leizman, Ben</author><author>Liu, Naijia</author><author>Möser, Malte</author><author>Mack, Andrew E.</author><author>Mahajan, Mayank</author><author>Mandell, Noah</author><author>Marahrens, Helge</author><author>Mercado-Garcia, Diana</author><author>Mocz, Viola</author><author>Mueller-Gastell, Katariina</author><author>Musse, Ahmed</author><author>Niu, Qiankun</author><author>Nowak, William</author><author>Omidvar, Hamidreza</author><author>Or, Andrew</author><author>Ouyang, Karen</author><author>Pinto, Katy M.</author><author>Porter, Ethan</author><author>Porter, Kristin E.</author><author>Qian, Crystal</author><author>Rauf, Tamkinat</author><author>Sargsyan, Anahit</author><author>Schaffner, Thomas</author><author>Schnabel, Landon</author><author>Schonfeld, Bryan</author><author>Sender, Ben</author><author>Tang, Jonathan D.</author><author>Tsurkov, Emma</author><author>van Loon, Austin</author><author>Varol, Onur</author><author>Wang, Xiafei</author><author>Wang, Zhi</author><author>Wang, Julia</author><author>Wang, Flora</author><author>Weissman, Samantha</author><author>Whitaker, Kirstie</author><author>Wolters, Maria K.</author><author>Woon, Wei Lee</author><author>Wu, James</author><author>Wu, Catherine</author><author>Yang, Kengran</author><author>Yin, Jingwen</author><author>Zhao, Bingyu</author><author>Zhu, Chenyun</author><author>Brooks-Gunn, Jeanne</author><author>Engelhardt, Barbara E.</author><author>Hardt, Moritz</author><author>Knox, Dean</author><author>Levy, Karen</author><author>Narayanan, Arvind</author><author>Stewart, Brandon M.</author><author>Watts, Duncan J.</author><author>McLanahan, Sara</author></authors></contributors><titles><title>Measuring the predictability of life outcomes with a scientific mass collaboration</title><secondary-title>Proceedings of the National Academy of Sciences</secondary-title></titles><periodical><full-title>Proceedings of the National Academy of Sciences</full-title></periodical><pages>8398-8403</pages><volume>117</volume><number>15</number><issue>15</issue><dates><year>2020</year><pub-dates><date>2020-04-14</date></pub-dates></dates><electronic-resource-num>10.1073/pnas.1915006117</electronic-resource-num><abstract>How predictable are life trajectories? We investigated this question with a scientific mass collaboration using the common task method; 160 teams built predictive models for six life outcomes using data from the Fragile Families and Child Wellbeing Study, a high-quality birth cohort study. Despite using a rich dataset and applying machine-learning methods optimized for prediction, the best predictions were not very accurate and were only slightly better than those from a simple benchmark model. Within each outcome, prediction error was strongly associated with the family being predicted and weakly associated with the technique used to generate the prediction. Overall, these results suggest practical limits to the predictability of life outcomes in some settings and illustrate the value of mass collaborations in the social sciences.</abstract><remote-database-name>pnas.org (Atypon)</remote-database-name><urls><web-urls><url>https://www.pnas.org/doi/10.1073/pnas.1915006117</url></web-urls></urls><access-date>2024-02-13 15:40:56</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Maier-Hein, Klaus H.</author><author>Neher, Peter F.</author><author>Houde, Jean-Christophe</author><author>Côté, Marc-Alexandre</author><author>Garyfallidis, Eleftherios</author><author>Zhong, Jidan</author><author>Chamberland, Maxime</author><author>Yeh, Fang-Cheng</author><author>Lin, Ying-Chia</author><author>Ji, Qing</author><author>Reddick, Wilburn E.</author><author>Glass, John O.</author><author>Chen, David Qixiang</author><author>Feng, Yuanjing</author><author>Gao, Chengfeng</author><author>Wu, Ye</author><author>Ma, Jieyan</author><author>He, Renjie</author><author>Li, Qiang</author><author>Westin, Carl-Fredrik</author><author>Deslauriers-Gauthier, Samuel</author><author>González, J. Omar Ocegueda</author><author>Paquette, Michael</author><author>St-Jean, Samuel</author><author>Girard, Gabriel</author><author>Rheault, François</author><author>Sidhu, Jasmeen</author><author>Tax, Chantal M. W.</author><author>Guo, Fenghua</author><author>Mesri, Hamed Y.</author><author>Dávid, Szabolcs</author><author>Froeling, Martijn</author><author>Heemskerk, Anneriet M.</author><author>Leemans, Alexander</author><author>Boré, Arnaud</author><author>Pinsard, Basile</author><author>Bedetti, Christophe</author><author>Desrosiers, Matthieu</author><author>Brambati, Simona</author><author>Doyon, Julien</author><author>Sarica, Alessia</author><author>Vasta, Roberta</author><author>Cerasa, Antonio</author><author>Quattrone, Aldo</author><author>Yeatman, Jason</author><author>Khan, Ali R.</author><author>Hodges, Wes</author><author>Alexander, Simon</author><author>Romascano, David</author><author>Barakovic, Muhamed</author><author>Auría, Anna</author><author>Esteban, Oscar</author><author>Lemkaddem, Alia</author><author>Thiran, Jean-Philippe</author><author>Cetingul, H. Ertan</author><author>Odry, Benjamin L.</author><author>Mailhe, Boris</author><author>Nadar, Mariappan S.</author><author>Pizzagalli, Fabrizio</author><author>Prasad, Gautam</author><author>Villalon-Reina, Julio E.</author><author>Galvis, Justin</author><author>Thompson, Paul M.</author><author>Requejo, Francisco De Santiago</author><author>Laguna, Pedro Luque</author><author>Lacerda, Luis Miguel</author><author>Barrett, Rachel</author><author>Dell’Acqua, Flavio</author><author>Catani, Marco</author><author>Petit, Laurent</author><author>Caruyer, Emmanuel</author><author>Daducci, Alessandro</author><author>Dyrby, Tim B.</author><author>Holland-Letz, Tim</author><author>Hilgetag, Claus C.</author><author>Stieltjes, Bram</author><author>Descoteaux, Maxime</author></authors></contributors><titles><title>The challenge of mapping the human connectome based on diffusion tractography</title><secondary-title>Nature Communications</secondary-title></titles><periodical><full-title>Nature Communications</full-title><abbr-1>Nat Commun</abbr-1></periodical><pages>1349</pages><volume>8</volume><dates><year>2017</year><pub-dates><date>2017-11-7</date></pub-dates></dates><isbn>2041-1723</isbn><electronic-resource-num>10.1038/s41467-017-01285-x</electronic-resource-num><abstract>Tractography based on non-invasive diffusion imaging is central to the study of human brain connectivity. To date, the approach has not been systematically validated in ground truth studies. Based on a simulated human brain data set with ground truth tracts, we organized an open international tractography challenge, which resulted in 96 distinct submissions from 20 research groups. Here, we report the encouraging finding that most state-of-the-art algorithms produce tractograms containing 90% of the ground truth bundles (to at least some extent). However, the same tractograms contain many more invalid than valid bundles, and half of these invalid bundles occur systematically across research groups. Taken together, our results demonstrate and confirm fundamental ambiguities inherent in tract reconstruction based on orientation information alone, which need to be considered when interpreting tractography and connectivity results. Our approach provides a novel framework for estimating reliability of tractography and encourages innovation to address its current limitations., Though tractography is widely used, it has not been systematically validated. Here, authors report results from 20 groups showing that many tractography algorithms produce both valid and invalid bundles.</abstract><remote-database-name>PubMed Central</remote-database-name><urls><web-urls><url>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5677006/</url></web-urls></urls><access-date>2024-02-13 15:39:42</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Hoogeveen, Suzanne</author><author>Sarafoglou, Alexandra</author><author>Aczel, Balazs</author><author>Aditya, Yonathan</author><author>Alayan, Alexandra J.</author><author>Allen, Peter J.</author><author>Altay, Sacha</author><author>Alzahawi, Shilaan</author><author>Amir, Yulmaida</author><author>Anthony, Francis-Vincent</author><author>Kwame Appiah, Obed</author><author>Atkinson, Quentin D.</author><author>Baimel, Adam</author><author>Balkaya-Ince, Merve</author><author>Balsamo, Michela</author><author>Banker, Sachin</author><author>Bartoš, František</author><author>Becerra, Mario</author><author>Beffara, Bertrand</author><author>Beitner, Julia</author><author>Bendixen, Theiss</author><author>Berkessel, Jana B.</author><author>Berniūnas, Renatas</author><author>Billet, Matthew I.</author><author>Billingsley, Joseph</author><author>Bortolini, Tiago</author><author>Breitsohl, Heiko</author><author>Bret, Amélie</author><author>Brown, Faith L.</author><author>Brown, Jennifer</author><author>Brumbaugh, Claudia C.</author><author>Buczny, Jacek</author><author>Bulbulia, Joseph</author><author>Caballero, Saúl</author><author>Carlucci, Leonardo</author><author>Carmichael, Cheryl L.</author><author>Cattaneo, Marco E. G. V.</author><author>Charles, Sarah J.</author><author>Claessens, Scott</author><author>Panagopoulos, Maxinne C.</author><author>Costa, Angelo Brandelli</author><author>Crone, Damien L.</author><author>Czoschke, Stefan</author><author>Czymara, Christian</author><author>D'Urso, E. Damiano</author><author>Dahlström, Örjan</author><author>Rosa, Anna Dalla</author><author>Danielsson, Henrik</author><author>De Ron, Jill</author><author>de Vries, Ymkje Anna</author><author>Dean, Kristy K.</author><author>Dik, Bryan J.</author><author>Disabato, David J.</author><author>Doherty, Jaclyn K.</author><author>Draws, Tim</author><author>Drouhot, Lucas</author><author>Dujmovic, Marin</author><author>Dunham, Yarrow</author><author>Ebert, Tobias</author><author>Edelsbrunner, Peter A.</author><author>Eerland, Anita</author><author>Elbaek, Christian T.</author><author>Farahmand, Shole</author><author>Farahmand, Hooman</author><author>Farias, Miguel</author><author>Feliccia, Abrey A.</author><author>Fischer, Kyle</author><author>Fischer, Ronald</author><author>Fisher-Thompson, Donna</author><author>Francis, Zoë</author><author>Frick, Susanne</author><author>Frisch, Lisa K.</author><author>Geraldes, Diogo</author><author>Gerdin, Emily</author><author>Geven, Linda</author><author>Ghasemi, Omid</author><author>Gielens, Erwin</author><author>Gligorić, Vukašin</author><author>Hagel, Kristin</author><author>Hajdu, Nandor</author><author>Hamilton, Hannah R.</author><author>Hamzah, Imaduddin</author><author>Hanel, Paul H. P.</author><author>Hawk, Christopher E.</author><author>K. Himawan, Karel</author><author>Holding, Benjamin C.</author><author>Homman, Lina E.</author><author>Ingendahl, Moritz</author><author>Inkilä, Hilla</author><author>Inman, Mary L.</author><author>Islam, Chris-Gabriel</author><author>Isler, Ozan</author><author>Izydorczyk, David</author><author>Jaeger, Bastian</author><author>Johnson, Kathryn A.</author><author>Jong, Jonathan</author><author>Karl, Johannes A.</author><author>Kaszubowski, Erikson</author><author>Katz, Benjamin A.</author><author>Keefer, Lucas A.</author><author>Kelchtermans, Stijn</author><author>Kelly, John M.</author><author>Klein, Richard A.</author><author>Kleinberg, Bennett</author><author>Knowles, Megan L.</author><author>Kołczyńska, Marta</author><author>Koller, Dave</author><author>Krasko, Julia</author><author>Kritzler, Sarah</author><author>Krypotos, Angelos-Miltiadis</author><author>Kyritsis, Thanos</author><author>L. Landes, Todd</author><author>Laukenmann, Ruben</author><author>Forsyth, Guy A. Lavender</author><author>Lazar, Aryeh</author><author>Lehman, Barbara J.</author><author>Levy, Neil</author><author>Lo, Ronda F.</author><author>Lodder, Paul</author><author>Lorenz, Jennifer</author><author>Łowicki, Paweł</author><author>Ly, Albert L.</author><author>Maassen, Esther</author><author>Magyar-Russell, Gina M.</author><author>Maier, Maximilian</author><author>Marsh, Dylan R.</author><author>Martinez, Nuria</author><author>Martinie, Marcellin</author><author>Martoyo, Ihan</author><author>Mason, Susan E.</author><author>Mauritsen, Anne Lundahl</author><author>McAleer, Phil</author><author>McCauley, Thomas</author><author>McCullough, Michael</author><author>McKay, Ryan</author><author>McMahon, Camilla M.</author><author>McNamara, Amelia A.</author><author>Means, Kira K.</author><author>Mercier, Brett</author><author>Mitkidis, Panagiotis</author><author>Monin, Benoît</author><author>Moon, Jordan W.</author><author>Moreau, David</author><author>Morgan, Jonathan</author><author>Murphy, James</author><author>Muscatt, George</author><author>Nägel, Christof</author><author>Nagy, Tamás</author><author>Nalborczyk, Ladislas</author><author>Nilsonne, Gustav</author><author>Noack, Pamina</author><author>Norenzayan, Ara</author><author>Nuijten, Michèle B.</author><author>Olsson-Collentine, Anton</author><author>Oviedo, Lluis</author><author>Pavlov, Yuri G.</author><author>Pawelski, James O.</author><author>Pearson, Hannah I.</author><author>Pedder, Hugo</author><author>Peetz, Hannah K.</author><author>Pinus, Michael</author><author>Pirutinsky, Steven</author><author>Polito, Vince</author><author>Porubanova, Michaela</author><author>Poulin, Michael J.</author><author>Prenoveau, Jason M.</author><author>Prince, Mark A.</author><author>Protzko, John</author><author>Pryor, Campbell</author><author>Purzycki, Benjamin G.</author><author>Qiu, Lin</author><author>Pütter, Julian Quevedo</author><author>Rabelo, André</author><author>Radell, Milen L.</author><author>Ramsay, Jonathan E.</author><author>Reid, Graham</author><author>J. Roberts, Andrew</author><author>Luna, Lindsey M. Root</author><author>Ross, Robert M.</author><author>Roszak, Piotr</author><author>Roy, Nirmal</author><author>Saarelainen, Suvi-Maria K.</author><author>Sasaki, Joni Y.</author><author>Schaumans, Catherine</author><author>Schivinski, Bruno</author><author>Schmitt, Marcel C.</author><author>Schnitker, Sarah A.</author><author>Schnuerch, Martin</author><author>Schreiner, Marcel R.</author><author>Schüttengruber, Victoria</author><author>Sebben, Simone</author><author>Segerstrom, Suzanne C.</author><author>Seryczyńska, Berenika</author><author>Shjoedt, Uffe</author><author>Simsek, Müge</author><author>Sleegers, Willem W. A.</author><author>Smith, Eliot R.</author><author>Sowden, Walter J.</author><author>Späth, Marion</author><author>Spörlein, Christoph</author><author>Stedden, William</author><author>Stoevenbelt, Andrea H.</author><author>Stuber, Simon</author><author>Sulik, Justin</author><author>Suwartono, Christiany</author><author>Syropoulos, Stylianos</author><author>Szaszi, Barnabas</author><author>Szecsi, Peter</author><author>Tappin, Ben M.</author><author>Tay, Louis</author><author>Thibault, Robert T.</author><author>Thompson, Burt</author><author>Thurn, Christian M.</author><author>Torralba, Josefa</author><author>Tuthill, Shelby D.</author><author>Ullein, Ann-Marie</author><author>Van Aert, Robbie C. M.</author><author>van Assen, Marcel A. L. M.</author><author>Van Cappellen, Patty</author><author>van den Akker, Olmo R.</author><author>Van der Cruyssen, Ine</author><author>Van der Noll, Jolanda</author><author>van Dongen, Noah N. N.</author><author>Van Lissa, Caspar J.</author><author>van Mulukom, Valerie</author><author>van Ravenzwaaij, Don</author><author>van Zyl, Casper J. J.</author><author>Ann Vaughn, Leigh</author><author>Većkalov, Bojana</author><author>Verschuere, Bruno</author><author>Vianello, Michelangelo</author><author>Vilanova, Felipe</author><author>Vishkin, Allon</author><author>Vogel, Vera</author><author>Vogelsmeier, Leonie V. D. E.</author><author>Watanabe, Shoko</author><author>White, Cindel J. M.</author><author>Wiebels, Kristina</author><author>Wiechert, Sera</author><author>Willett, Zachary Z.</author><author>Witkowiak, Maciej</author><author>Witvliet, Charlotte V. O.</author><author>Wiwad, Dylan</author><author>Wuyts, Robin</author><author>Xygalatas, Dimitris</author><author>Yang, Xin</author><author>Yeo, Darren J.</author><author>Yilmaz, Onurcan</author><author>Zarzeczna, Natalia</author><author>Zhao, Yitong</author><author>Zijlmans, Josjan</author><author>van Elk, Michiel</author><author>Wagenmakers, Eric-Jan</author></authors></contributors><titles><title>A many-analysts approach to the relation between religiosity and well-being</title><secondary-title>Religion, Brain &amp; Behavior</secondary-title></titles><periodical><full-title>Religion, Brain &amp; Behavior</full-title></periodical><pages>237-283</pages><volume>13</volume><number>3</number><issue>3</issue><keywords><keyword>Health</keyword><keyword>many analysts</keyword><keyword>open science</keyword><keyword>religion</keyword></keywords><dates><year>2023</year><pub-dates><date>2023-07-03</date></pub-dates></dates><isbn>2153-599X</isbn><electronic-resource-num>10.1080/2153599X.2022.2070255</electronic-resource-num><abstract>The relation between religiosity and well-being is one of the most researched topics in the psychology of religion, yet the directionality and robustness of the effect remains debated. Here, we adopted a many-analysts approach to assess the robustness of this relation based on a new cross-cultural dataset (N=10,535 participants from 24 countries). We recruited 120 analysis teams to investigate (1) whether religious people self-report higher well-being, and (2) whether the relation between religiosity and self-reported well-being depends on perceived cultural norms of religion (i.e., whether it is considered normal and desirable to be religious in a given country). In a two-stage procedure, the teams first created an analysis plan and then executed their planned analysis on the data. For the first research question, all but 3 teams reported positive effect sizes with credible/confidence intervals excluding zero (median reported β=0.120). For the second research question, this was the case for 65% of the teams (median reported β=0.039). While most teams applied (multilevel) linear regression models, there was considerable variability in the choice of items used to construct the independent variables, the dependent variable, and the included covariates.</abstract><remote-database-name>Taylor and Francis+NEJM</remote-database-name><urls><web-urls><url>https://doi.org/10.1080/2153599X.2022.2070255</url></web-urls></urls><access-date>2024-02-13 15:38:52</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Coretta, Stefano</author><author>Casillas, Joseph V.</author><author>Roessig, Simon</author><author>Franke, Michael</author><author>Ahn, Byron</author><author>Al-Hoorie, Ali H.</author><author>Al-Tamimi, Jalal</author><author>Alotaibi, Najd E.</author><author>AlShakhori, Mohammed K.</author><author>Altmiller, Ruth M.</author><author>Arantes, Pablo</author><author>Athanasopoulou, Angeliki</author><author>Baese-Berk, Melissa M.</author><author>Bailey, George</author><author>Sangma, Cheman Baira A</author><author>Beier, Eleonora J.</author><author>Benavides, Gabriela M.</author><author>Benker, Nicole</author><author>BensonMeyer, Emelia P.</author><author>Benway, Nina R.</author><author>Berry, Grant M.</author><author>Bing, Liwen</author><author>Bjorndahl, Christina</author><author>Bolyanatz, Mariška</author><author>Braver, Aaron</author><author>Brown, Violet A.</author><author>Brown, Alicia M.</author><author>Brugos, Alejna</author><author>Buchanan, Erin M.</author><author>Butlin, Tanna</author><author>Buxó-Lugo, Andrés</author><author>Caillol, Coline</author><author>Cangemi, Francesco</author><author>Carignan, Christopher</author><author>Carraturo, Sita</author><author>Caudrelier, Tiphaine</author><author>Chodroff, Eleanor</author><author>Cohn, Michelle</author><author>Cronenberg, Johanna</author><author>Crouzet, Olivier</author><author>Dagar, Erica L.</author><author>Dawson, Charlotte</author><author>Diantoro, Carissa A.</author><author>Dokovova, Marie</author><author>Drake, Shiloh</author><author>Du, Fengting</author><author>Dubuis, Margaux</author><author>Duême, Florent</author><author>Durward, Matthew</author><author>Egurtzegi, Ander</author><author>Elsherif, Mahmoud M.</author><author>Esser, Janina</author><author>Ferragne, Emmanuel</author><author>Ferreira, Fernanda</author><author>Fink, Lauren K.</author><author>Finley, Sara</author><author>Foster, Kurtis</author><author>Foulkes, Paul</author><author>Franzke, Rosa</author><author>Frazer-McKee, Gabriel</author><author>Fromont, Robert</author><author>García, Christina</author><author>Geller, Jason</author><author>Grasso, Camille L.</author><author>Greca, Pia</author><author>Grice, Martine</author><author>Grose-Hodge, Magdalena S.</author><author>Gully, Amelia J.</author><author>Halfacre, Caitlin</author><author>Hauser, Ivy</author><author>Hay, Jen</author><author>Haywood, Robert</author><author>Hellmuth, Sam</author><author>Hilger, Allison I.</author><author>Holliday, Nicole</author><author>Hoogland, Damar</author><author>Huang, Yaqian</author><author>Hughes, Vincent</author><author>Icardo Isasa, Ane</author><author>Ilchovska, Zlatomira G.</author><author>Jeon, Hae-Sung</author><author>Jones, Jacq</author><author>Junges, Mágat N.</author><author>Kaefer, Stephanie</author><author>Kaland, Constantijn</author><author>Kelley, Matthew C.</author><author>Kelly, Niamh E.</author><author>Kettig, Thomas</author><author>Khattab, Ghada</author><author>Koolen, Ruud</author><author>Krahmer, Emiel</author><author>Krajewska, Dorota</author><author>Krug, Andreas</author><author>Kumar, Abhilasha A.</author><author>Lander, Anna</author><author>Lentz, Tomas O.</author><author>Li, Wanyin</author><author>Li, Yanyu</author><author>Lialiou, Maria</author><author>Lima, Ronaldo M.</author><author>Lo, Justin J. H.</author><author>Lopez Otero, Julio Cesar</author><author>Mackay, Bradley</author><author>MacLeod, Bethany</author><author>Mallard, Mel</author><author>McConnellogue, Carol-Ann Mary</author><author>Moroz, George</author><author>Murali, Mridhula</author><author>Nalborczyk, Ladislas</author><author>Nenadić, Filip</author><author>Nieder, Jessica</author><author>Nikolić, Dušan</author><author>Nogueira, Francisco G. S.</author><author>Offerman, Heather M.</author><author>Passoni, Elisa</author><author>Pélissier, Maud</author><author>Perry, Scott J.</author><author>Pfiffner, Alexandra M.</author><author>Proctor, Michael</author><author>Rhodes, Ryan</author><author>Rodríguez, Nicole</author><author>Roepke, Elizabeth</author><author>Röer, Jan P.</author><author>Sbacco, Lucia</author><author>Scarborough, Rebecca</author><author>Schaeffler, Felix</author><author>Schleef, Erik</author><author>Schmitz, Dominic</author><author>Shiryaev, Alexander</author><author>Sóskuthy, Márton</author><author>Spaniol, Malin</author><author>Stanley, Joseph A.</author><author>Strickler, Alyssa</author><author>Tavano, Alessandro</author><author>Tomaschek, Fabian</author><author>Tucker, Benjamin V.</author><author>Turnbull, Rory</author><author>Ugwuanyi, Kingsley O.</author><author>Urrestarazu-Porta, Iñigo</author><author>van de Vijver, Ruben</author><author>Van Engen, Kristin J.</author><author>van Miltenburg, Emiel</author><author>Wang, Bruce Xiao</author><author>Warner, Natasha</author><author>Wehrle, Simon</author><author>Westerbeek, Hans</author><author>Wiener, Seth</author><author>Winters, Stephen</author><author>Wong, Sidney G.-J.</author><author>Wood, Anna</author><author>Wottawa, Jane</author><author>Xu, Chenzi</author><author>Zárate-Sández, Germán</author><author>Zellou, Georgia</author><author>Zhang, Cong</author><author>Zhu, Jian</author><author>Roettger, Timo B.</author></authors></contributors><titles><title>Multidimensional Signals and Analytic Flexibility: Estimating Degrees of Freedom in Human-Speech Analyses</title><secondary-title>Advances in Methods and Practices in Psychological Science</secondary-title><short-title>Multidimensional Signals and Analytic Flexibility</short-title></titles><periodical><full-title>Advances in Methods and Practices in Psychological Science</full-title></periodical><pages>25152459231162567</pages><volume>6</volume><number>3</number><issue>3</issue><dates><year>2023</year><pub-dates><date>2023-07-01</date></pub-dates></dates><isbn>2515-2459</isbn><electronic-resource-num>10.1177/25152459231162567</electronic-resource-num><abstract>Recent empirical studies have highlighted the large degree of analytic flexibility in data analysis that can lead to substantially different conclusions based on the same data set. Thus, researchers have expressed their concerns that these researcher degrees of freedom might facilitate bias and can lead to claims that do not stand the test of time. Even greater flexibility is to be expected in fields in which the primary data lend themselves to a variety of possible operationalizations. The multidimensional, temporally extended nature of speech constitutes an ideal testing ground for assessing the variability in analytic approaches, which derives not only from aspects of statistical modeling but also from decisions regarding the quantification of the measured behavior. In this study, we gave the same speech-production data set to 46 teams of researchers and asked them to answer the same research question, resulting in substantial variability in reported effect sizes and their interpretation. Using Bayesian meta-analytic tools, we further found little to no evidence that the observed variability can be explained by analysts’ prior beliefs, expertise, or the perceived quality of their analyses. In light of this idiosyncratic variability, we recommend that researchers more transparently share details of their analysis, strengthen the link between theoretical construct and quantitative system, and calibrate their (un)certainty in their conclusions.</abstract><remote-database-name>SAGE Journals</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1177/25152459231162567</url></web-urls></urls><access-date>2024-02-13 15:34:18</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Botvinik-Nezer, Rotem</author><author>Holzmeister, Felix</author><author>Camerer, Colin F.</author><author>Dreber, Anna</author><author>Huber, Juergen</author><author>Johannesson, Magnus</author><author>Kirchler, Michael</author><author>Iwanir, Roni</author><author>Mumford, Jeanette A.</author><author>Adcock, R. Alison</author><author>Avesani, Paolo</author><author>Baczkowski, Blazej M.</author><author>Bajracharya, Aahana</author><author>Bakst, Leah</author><author>Ball, Sheryl</author><author>Barilari, Marco</author><author>Bault, Nadège</author><author>Beaton, Derek</author><author>Beitner, Julia</author><author>Benoit, Roland G.</author><author>Berkers, Ruud M. W. J.</author><author>Bhanji, Jamil P.</author><author>Biswal, Bharat B.</author><author>Bobadilla-Suarez, Sebastian</author><author>Bortolini, Tiago</author><author>Bottenhorn, Katherine L.</author><author>Bowring, Alexander</author><author>Braem, Senne</author><author>Brooks, Hayley R.</author><author>Brudner, Emily G.</author><author>Calderon, Cristian B.</author><author>Camilleri, Julia A.</author><author>Castrellon, Jaime J.</author><author>Cecchetti, Luca</author><author>Cieslik, Edna C.</author><author>Cole, Zachary J.</author><author>Collignon, Olivier</author><author>Cox, Robert W.</author><author>Cunningham, William A.</author><author>Czoschke, Stefan</author><author>Dadi, Kamalaker</author><author>Davis, Charles P.</author><author>Luca, Alberto De</author><author>Delgado, Mauricio R.</author><author>Demetriou, Lysia</author><author>Dennison, Jeffrey B.</author><author>Di, Xin</author><author>Dickie, Erin W.</author><author>Dobryakova, Ekaterina</author><author>Donnat, Claire L.</author><author>Dukart, Juergen</author><author>Duncan, Niall W.</author><author>Durnez, Joke</author><author>Eed, Amr</author><author>Eickhoff, Simon B.</author><author>Erhart, Andrew</author><author>Fontanesi, Laura</author><author>Fricke, G. Matthew</author><author>Fu, Shiguang</author><author>Galván, Adriana</author><author>Gau, Remi</author><author>Genon, Sarah</author><author>Glatard, Tristan</author><author>Glerean, Enrico</author><author>Goeman, Jelle J.</author><author>Golowin, Sergej A. E.</author><author>González-García, Carlos</author><author>Gorgolewski, Krzysztof J.</author><author>Grady, Cheryl L.</author><author>Green, Mikella A.</author><author>Guassi Moreira, João F.</author><author>Guest, Olivia</author><author>Hakimi, Shabnam</author><author>Hamilton, J. Paul</author><author>Hancock, Roeland</author><author>Handjaras, Giacomo</author><author>Harry, Bronson B.</author><author>Hawco, Colin</author><author>Herholz, Peer</author><author>Herman, Gabrielle</author><author>Heunis, Stephan</author><author>Hoffstaedter, Felix</author><author>Hogeveen, Jeremy</author><author>Holmes, Susan</author><author>Hu, Chuan-Peng</author><author>Huettel, Scott A.</author><author>Hughes, Matthew E.</author><author>Iacovella, Vittorio</author><author>Iordan, Alexandru D.</author><author>Isager, Peder M.</author><author>Isik, Ayse I.</author><author>Jahn, Andrew</author><author>Johnson, Matthew R.</author><author>Johnstone, Tom</author><author>Joseph, Michael J. E.</author><author>Juliano, Anthony C.</author><author>Kable, Joseph W.</author><author>Kassinopoulos, Michalis</author><author>Koba, Cemal</author><author>Kong, Xiang-Zhen</author><author>Koscik, Timothy R.</author><author>Kucukboyaci, Nuri Erkut</author><author>Kuhl, Brice A.</author><author>Kupek, Sebastian</author><author>Laird, Angela R.</author><author>Lamm, Claus</author><author>Langner, Robert</author><author>Lauharatanahirun, Nina</author><author>Lee, Hongmi</author><author>Lee, Sangil</author><author>Leemans, Alexander</author><author>Leo, Andrea</author><author>Lesage, Elise</author><author>Li, Flora</author><author>Li, Monica Y. C.</author><author>Lim, Phui Cheng</author><author>Lintz, Evan N.</author><author>Liphardt, Schuyler W.</author><author>Losecaat Vermeer, Annabel B.</author><author>Love, Bradley C.</author><author>Mack, Michael L.</author><author>Malpica, Norberto</author><author>Marins, Theo</author><author>Maumet, Camille</author><author>McDonald, Kelsey</author><author>McGuire, Joseph T.</author><author>Melero, Helena</author><author>Méndez Leal, Adriana S.</author><author>Meyer, Benjamin</author><author>Meyer, Kristin N.</author><author>Mihai, Glad</author><author>Mitsis, Georgios D.</author><author>Moll, Jorge</author><author>Nielson, Dylan M.</author><author>Nilsonne, Gustav</author><author>Notter, Michael P.</author><author>Olivetti, Emanuele</author><author>Onicas, Adrian I.</author><author>Papale, Paolo</author><author>Patil, Kaustubh R.</author><author>Peelle, Jonathan E.</author><author>Pérez, Alexandre</author><author>Pischedda, Doris</author><author>Poline, Jean-Baptiste</author><author>Prystauka, Yanina</author><author>Ray, Shruti</author><author>Reuter-Lorenz, Patricia A.</author><author>Reynolds, Richard C.</author><author>Ricciardi, Emiliano</author><author>Rieck, Jenny R.</author><author>Rodriguez-Thompson, Anais M.</author><author>Romyn, Anthony</author><author>Salo, Taylor</author><author>Samanez-Larkin, Gregory R.</author><author>Sanz-Morales, Emilio</author><author>Schlichting, Margaret L.</author><author>Schultz, Douglas H.</author><author>Shen, Qiang</author><author>Sheridan, Margaret A.</author><author>Silvers, Jennifer A.</author><author>Skagerlund, Kenny</author><author>Smith, Alec</author><author>Smith, David V.</author><author>Sokol-Hessner, Peter</author><author>Steinkamp, Simon R.</author><author>Tashjian, Sarah M.</author><author>Thirion, Bertrand</author><author>Thorp, John N.</author><author>Tinghög, Gustav</author><author>Tisdall, Loreen</author><author>Tompson, Steven H.</author><author>Toro-Serey, Claudio</author><author>Torre Tresols, Juan Jesus</author><author>Tozzi, Leonardo</author><author>Truong, Vuong</author><author>Turella, Luca</author><author>van ‘t Veer, Anna E.</author><author>Verguts, Tom</author><author>Vettel, Jean M.</author><author>Vijayarajah, Sagana</author><author>Vo, Khoi</author><author>Wall, Matthew B.</author><author>Weeda, Wouter D.</author><author>Weis, Susanne</author><author>White, David J.</author><author>Wisniewski, David</author><author>Xifra-Porxas, Alba</author><author>Yearling, Emily A.</author><author>Yoon, Sangsuk</author><author>Yuan, Rui</author><author>Yuen, Kenneth S. L.</author><author>Zhang, Lei</author><author>Zhang, Xu</author><author>Zosky, Joshua E.</author><author>Nichols, Thomas E.</author><author>Poldrack, Russell A.</author><author>Schonberg, Tom</author></authors></contributors><titles><title>Variability in the analysis of a single neuroimaging dataset by many teams</title><secondary-title>Nature</secondary-title></titles><periodical><full-title>Nature</full-title></periodical><pages>84-88</pages><volume>582</volume><number>7810</number><issue>7810</issue><keywords><keyword>Decision</keyword><keyword>Decision making</keyword><keyword>Human behaviour</keyword><keyword>Scientific community</keyword></keywords><dates><year>2020</year><pub-dates><date>2020-06</date></pub-dates></dates><isbn>1476-4687</isbn><electronic-resource-num>10.1038/s41586-020-2314-9</electronic-resource-num><abstract>Data analysis workflows in many scientific domains have become increasingly complex and flexible. Here we assess the effect of this flexibility on the results of functional magnetic resonance imaging by asking 70 independent teams to analyse the same dataset, testing the same 9 ex-ante hypotheses1. The flexibility of analytical approaches is exemplified by the fact that no two teams chose identical workflows to analyse the data. This flexibility resulted in sizeable variation in the results of hypothesis tests, even for teams whose statistical maps were highly correlated at intermediate stages of the analysis pipeline. Variation in reported results was related to several aspects of analysis methodology. Notably, a meta-analytical approach that aggregated information across teams yielded a significant consensus in activated regions. Furthermore, prediction markets of researchers in the field revealed an overestimation of the likelihood of significant findings, even by researchers with direct knowledge of the dataset2–5. Our findings show that analytical flexibility can have substantial effects on scientific conclusions, and identify factors that may be related to variability in the analysis of functional magnetic resonance imaging. The results emphasize the importance of validating and sharing complex analysis workflows, and demonstrate the need for performing and reporting multiple analyses of the same data. Potential approaches that could be used to mitigate issues related to analytical variability are discussed.</abstract><remote-database-name>www.nature.com</remote-database-name><language>en</language><urls><web-urls><url>https://www.nature.com/articles/s41586-020-2314-9</url></web-urls></urls><access-date>2024-02-13 15:27:57</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Bastiaansen, Jojanneke A.</author><author>Kunkels, Yoram K.</author><author>Blaauw, Frank J.</author><author>Boker, Steven M.</author><author>Ceulemans, Eva</author><author>Chen, Meng</author><author>Chow, Sy-Miin</author><author>de Jonge, Peter</author><author>Emerencia, Ando C.</author><author>Epskamp, Sacha</author><author>Fisher, Aaron J.</author><author>Hamaker, Ellen L.</author><author>Kuppens, Peter</author><author>Lutz, Wolfgang</author><author>Meyer, M. Joseph</author><author>Moulder, Robert</author><author>Oravecz, Zita</author><author>Riese, Harriëtte</author><author>Rubel, Julian</author><author>Ryan, Oisín</author><author>Servaas, Michelle N.</author><author>Sjobeck, Gustav</author><author>Snippe, Evelien</author><author>Trull, Timothy J.</author><author>Tschacher, Wolfgang</author><author>van der Veen, Date C.</author><author>Wichers, Marieke</author><author>Wood, Phillip K.</author><author>Woods, William C.</author><author>Wright, Aidan G. C.</author><author>Albers, Casper J.</author><author>Bringmann, Laura F.</author></authors></contributors><titles><title>Time to get personal? The impact of researchers choices on the selection of treatment targets using the experience sampling methodology</title><secondary-title>Journal of Psychosomatic Research</secondary-title><short-title>Time to get personal?</short-title></titles><periodical><full-title>Journal of Psychosomatic Research</full-title><abbr-1>Journal of Psychosomatic Research</abbr-1></periodical><pages>110211</pages><volume>137</volume><keywords><keyword>Crowdsourcing science</keyword><keyword>Electronic diary</keyword><keyword>Mental disorders</keyword><keyword>Personalized medicine</keyword><keyword>Psychological networks</keyword><keyword>Time-series analysis</keyword></keywords><dates><year>2020</year><pub-dates><date>2020-10-01</date></pub-dates></dates><isbn>0022-3999</isbn><electronic-resource-num>10.1016/j.jpsychores.2020.110211</electronic-resource-num><abstract>Objective&#xD;One of the promises of the experience sampling methodology (ESM) is that a statistical analysis of an individual's emotions, cognitions and behaviors in everyday-life could be used to identify relevant treatment targets. A requisite for clinical implementation is that outcomes of such person-specific time-series analyses are not wholly contingent on the researcher performing them.&#xD;Methods&#xD;To evaluate this, we crowdsourced the analysis of one individual patient's ESM data to 12 prominent research teams, asking them what symptom(s) they would advise the treating clinician to target in subsequent treatment.&#xD;Results&#xD;Variation was evident at different stages of the analysis, from preprocessing steps (e.g., variable selection, clustering, handling of missing data) to the type of statistics and rationale for selecting targets. Most teams did include a type of vector autoregressive model, examining relations between symptoms over time. Although most teams were confident their selected targets would provide useful information to the clinician, not one recommendation was similar: both the number (0–16) and nature of selected targets varied widely.&#xD;Conclusion&#xD;This study makes transparent that the selection of treatment targets based on personalized models using ESM data is currently highly conditional on subjective analytical choices and highlights key conceptual and methodological issues that need to be addressed in moving towards clinical implementation.</abstract><remote-database-name>ScienceDirect</remote-database-name><urls><web-urls><url>https://www.sciencedirect.com/science/article/pii/S002239992030773X</url></web-urls></urls><access-date>2024-02-13 15:25:23</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Jaric, Ivana</author><author>Voelkl, Bernhard</author><author>Amrein, Irmgard</author><author>Wolfer, David P.</author><author>Novak, Janja</author><author>Detotto, Carlotta</author><author>Weber-Stadlbauer, Ulrike</author><author>Meyer, Urs</author><author>Manuella, Francesca</author><author>Mansuy, Isabelle M.</author><author>Würbel, Hanno</author></authors></contributors><titles><title>Using mice from different breeding sites fails to improve replicability of results from single-laboratory studies</title><secondary-title>Lab Animal</secondary-title></titles><periodical><full-title>Lab Animal</full-title><abbr-1>Lab Anim</abbr-1></periodical><pages>18-22</pages><volume>53</volume><number>1</number><issue>1</issue><keywords><keyword>Animal behaviour</keyword><keyword>Robustness</keyword></keywords><dates><year>2024</year><pub-dates><date>2024-01</date></pub-dates></dates><isbn>1548-4475</isbn><electronic-resource-num>10.1038/s41684-023-01307-w</electronic-resource-num><abstract>Theoretical and empirical evidence indicates that low external validity due to rigorous standardization of study populations is a cause of poor replicability in animal research. Here we report a multi-laboratory study aimed at investigating whether heterogenization of study populations by using animals from different breeding sites increases the replicability of results from single-laboratory studies. We used male C57BL/6J mice from six different breeding sites to test a standardized against a heterogenized (HET) study design in six independent replicate test laboratories. For the standardized design, each laboratory ordered mice from a single breeding site (each laboratory from a different one), while for the HET design, each laboratory ordered proportionate numbers of mice from the five remaining breeding sites. To test our hypothesis, we assessed 14 outcome variables, including body weight, behavioral measures obtained from a single session on an elevated plus maze, and clinical blood parameters. Both breeding site and test laboratory affected variation in outcome variables, but the effect of test laboratory was more pronounced for most outcome variables. Moreover, heterogenization of study populations by breeding site (HET) did not reduce variation in outcome variables between test laboratories, which was most likely due to the fact that breeding site had only little effect on variation in outcome variables, thereby limiting the scope for HET to reduce between-lab variation. We conclude that heterogenization of study populations by breeding site has limited capacity for improving the replicability of results from single-laboratory animal studies.</abstract><remote-database-name>www.nature.com</remote-database-name><language>en</language><urls><web-urls><url>https://www.nature.com/articles/s41684-023-01307-w</url></web-urls></urls><access-date>2024-02-13 13:32:31</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Huntington-Klein, Nick</author><author>Arenas, Andreu</author><author>Beam, Emily</author><author>Bertoni, Marco</author><author>Bloem, Jeffrey R.</author><author>Burli, Pralhad</author><author>Chen, Naibin</author><author>Grieco, Paul</author><author>Ekpe, Godwin</author><author>Pugatch, Todd</author><author>Saavedra, Martin</author><author>Stopnitzky, Yaniv</author></authors></contributors><titles><title>The influence of hidden researcher decisions in applied microeconomics</title><secondary-title>Economic Inquiry</secondary-title></titles><periodical><full-title>Economic Inquiry</full-title></periodical><pages>944-960</pages><volume>59</volume><number>3</number><issue>3</issue><dates><year>2021</year><pub-dates><date>2021</date></pub-dates></dates><isbn>1465-7295</isbn><electronic-resource-num>10.1111/ecin.12992</electronic-resource-num><abstract>Researchers make hundreds of decisions about data collection, preparation, and analysis in their research. We use a many-analysts approach to measure the extent and impact of these decisions. Two published causal empirical results are replicated by seven replicators each. We find large differences in data preparation and analysis decisions, many of which would not likely be reported in a publication. No two replicators reported the same sample size. Statistical significance varied across replications, and for one of the studies the effect's sign varied as well. The standard deviation of estimates across replications was 3–4 times the mean reported standard error.</abstract><remote-database-name>Wiley Online Library</remote-database-name><language>en</language><urls><web-urls><url>https://onlinelibrary.wiley.com/doi/abs/10.1111/ecin.12992</url></web-urls></urls><access-date>2024-02-11 18:21:34</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Amaral, Olavo B</author><author>Neves, Kleber</author><author>Wasilewska-Sampaio, Ana P</author><author>Carneiro, Clarissa FD</author></authors><secondary-authors><author>Rodgers, Peter</author><author>Errington, Timothy M</author><author>Klein, Richard</author></secondary-authors></contributors><titles><title>The Brazilian Reproducibility Initiative</title><secondary-title>eLife</secondary-title></titles><periodical><full-title>eLife</full-title></periodical><pages>e41602</pages><volume>8</volume><keywords><keyword>Brazil</keyword><keyword>biomedical research</keyword><keyword>metascience</keyword><keyword>open science</keyword><keyword>replication</keyword><keyword>reproducibility</keyword></keywords><dates><year>2019</year><pub-dates><date>2019-02-05</date></pub-dates></dates><isbn>2050-084X</isbn><electronic-resource-num>10.7554/eLife.41602</electronic-resource-num><abstract>Most efforts to estimate the reproducibility of published findings have focused on specific areas of research, even though science is usually assessed and funded on a regional or national basis. Here we describe a project to assess the reproducibility of findings in biomedical science published by researchers based in Brazil. The Brazilian Reproducibility Initiative is a systematic, multicenter effort to repeat between 60 and 100 experiments: the project will focus on a set of common methods, repeating each experiment in three different laboratories from a countrywide network. The results, due in 2021, will allow us to estimate the level of reproducibility of biomedical science in Brazil, and to investigate what aspects of the published literature might help to predict whether a finding is reproducible.</abstract><remote-database-name>eLife</remote-database-name><urls><web-urls><url>https://doi.org/10.7554/eLife.41602</url></web-urls></urls><access-date>2024-02-13 13:45:51</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Alipourfard, Nazanin</author><author>Arendt, Beatrix</author><author>Benjamin, Daniel M.</author><author>Benkler, Noam</author><author>Bishop, Michael</author><author>Burstein, Mark</author><author>Bush, Martin</author><author>Caverlee, James</author><author>Chen, Yiling</author><author>Clark, Chae</author><author>Almenberg, Anna Dreber</author><author>Errington, Timothy M.</author><author>Fidler, Fiona</author><author>Field, Samuel</author><author>Fox [SCORE, Nicholas</author><author>Frank, Aaron</author><author>Fraser, Hannah</author><author>Friedman, Scott</author><author>Gelman, Ben</author><author>Gentile, James</author><author>Giles, C. Lee</author><author>Gordon, Michael B.</author><author>Gordon-Sarney, Reed</author><author>Griffin, Christopher</author><author>Gulden, Timothy</author><author>Hahn, Krystal</author><author>Hartman, Robert</author><author>Holzmeister, Felix</author><author>Hu, Xia Ben</author><author>Johannesson, Magnus</author><author>Kezar, Lee</author><author>Struhl, Melissa Kline</author><author>Kuter, Ugur</author><author>Kwasnica, Anthony M.</author><author>Lee, Dong-Ho</author><author>Lerman, Kristina</author><author>Liu, Yang</author><author>Loomas, Zachary</author><author>Luis [SCORE, Bri</author><author>Magnusson, Ian</author><author>Miske, Olivia</author><author>Mody, Fallon</author><author>Morstatter, Fred</author><author>Nosek, Brian A.</author><author>Parsons, Elan Simon</author><author>Pennock, David</author><author>Pfeiffer, Thomas</author><author>Pujara, Jay</author><author>Rajtmajer, Sarah</author><author>Ren, Xiang</author><author>Salinas, Abel</author><author>Selvam, Ravi Kiran</author><author>Shipman, Frank</author><author>Silverstein, Priya</author><author>Sprenger, Amber</author><author>Squicciarini, Anna Ms</author><author>Stratman, Steve</author><author>Sun, Kexuan</author><author>Tikoo, Saatvik</author><author>Twardy, Charles R.</author><author>Tyner, Andrew</author><author>Viganola, Domenico</author><author>Wang, Juntao</author><author>Wilkinson, David Peter</author><author>Wintle, Bonnie</author><author>Wu, Jian</author></authors></contributors><titles><title>Systematizing Confidence in Open Research and Evidence (SCORE)</title></titles><dates><year>2024</year><pub-dates><date>2024-02-13</date></pub-dates></dates><electronic-resource-num>10.31235/osf.io/46mnb</electronic-resource-num><abstract>Assessing the credibility of research claims is a central, continuous, and laborious part of the scientific process. Credibility assessment strategies range from expert judgment to aggregating existing evidence to systematic replication efforts. Such assessments can require substantial time and effort. Research progress could be accelerated if there were rapid, scalable, accurate credibility indicators to guide attention and resource allocation for further assessment. The SCORE program is creating and validating algorithms to provide confidence scores for research claims at scale. To investigate the viability of scalable tools, teams are creating: a database of claims from papers in the social and behavioral sciences; expert and machine generated estimates of credibility; and, evidence of reproducibility, robustness, and replicability to validate the estimates. Beyond the primary research objective, the data and artifacts generated from this program will be openly shared and provide an unprecedented opportunity to examine research credibility and evidence.</abstract><remote-database-name>osf.io</remote-database-name><language>en-us</language><urls><web-urls><url>https://osf.io/46mnb</url></web-urls></urls><access-date>2024-02-13 13:34:02</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Arroyo-Araujo, María</author><author>Voelkl, Bernhard</author><author>Laloux, Clément</author><author>Novak, Janja</author><author>Koopmans, Bastijn</author><author>Waldron, Ann-Marie</author><author>Seiffert, Isabel</author><author>Stirling, Helen</author><author>Aulehner, Katharina</author><author>Janhunen, Sanna K.</author><author>Ramboz, Sylvie</author><author>Potschka, Heidrun</author><author>Holappa, Johanna</author><author>Fine, Tania</author><author>Loos, Maarten</author><author>Boulanger, Bruno</author><author>Würbel, Hanno</author><author>Kas, Martien J.</author></authors></contributors><titles><title>Systematic assessment of the replicability and generalizability of preclinical findings: Impact of protocol harmonization across laboratory sites</title><secondary-title>PLOS Biology</secondary-title><short-title>Systematic assessment of the replicability and generalizability of preclinical findings</short-title></titles><periodical><full-title>PLOS Biology</full-title><abbr-1>PLOS Biology</abbr-1></periodical><pages>e3001886</pages><volume>20</volume><number>11</number><issue>11</issue><keywords><keyword>Biological laboratories</keyword><keyword>Biological locomotion</keyword><keyword>Drug interactions</keyword><keyword>Drug therapy</keyword><keyword>Phenotypes</keyword><keyword>Research laboratories</keyword><keyword>Statistical data</keyword><keyword>Tails</keyword></keywords><dates><year>2022</year><pub-dates><date>Nov 23, 2022</date></pub-dates></dates><isbn>1545-7885</isbn><electronic-resource-num>10.1371/journal.pbio.3001886</electronic-resource-num><abstract>The influence of protocol standardization between laboratories on their replicability of preclinical results has not been addressed in a systematic way. While standardization is considered good research practice as a means to control for undesired external noise (i.e., highly variable results), some reports suggest that standardized protocols may lead to idiosyncratic results, thus undermining replicability. Through the EQIPD consortium, a multi-lab collaboration between academic and industry partners, we aimed to elucidate parameters that impact the replicability of preclinical animal studies. To this end, 3 experimental protocols were implemented across 7 laboratories. The replicability of results was determined using the distance travelled in an open field after administration of pharmacological compounds known to modulate locomotor activity (MK-801, diazepam, and clozapine) in C57BL/6 mice as a worked example. The goal was to determine whether harmonization of study protocols across laboratories improves the replicability of the results and whether replicability can be further improved by systematic variation (heterogenization) of 2 environmental factors (time of testing and light intensity during testing) within laboratories. Protocols were tested in 3 consecutive stages and differed in the extent of harmonization across laboratories and standardization within laboratories: stage 1, minimally aligned across sites (local protocol); stage 2, fully aligned across sites (harmonized protocol) with and without systematic variation (standardized and heterogenized cohort); and stage 3, fully aligned across sites (standardized protocol) with a different compound. All protocols resulted in consistent treatment effects across laboratories, which were also replicated within laboratories across the different stages. Harmonization of protocols across laboratories reduced between-lab variability substantially compared to each lab using their local protocol. In contrast, the environmental factors chosen to introduce systematic variation within laboratories did not affect the behavioral outcome. Therefore, heterogenization did not reduce between-lab variability further compared to the harmonization of the standardized protocol. Altogether, these findings demonstrate that subtle variations between lab-specific study protocols may introduce variation across independent replicate studies even after protocol harmonization and that systematic heterogenization of environmental factors may not be sufficient to account for such between-lab variation. Differences in replicability of results within and between laboratories highlight the ubiquity of study-specific variation due to between-lab variability, the importance of transparent and fine-grained reporting of methodologies and research protocols, and the importance of independent study replication.</abstract><remote-database-name>PLoS Journals</remote-database-name><language>en</language><urls><web-urls><url>https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001886</url></web-urls></urls><access-date>2024-02-13 13:31:37</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Fišar, Miloš</author><author>Greiner, Ben</author><author>Huber, Christoph</author><author>Katok, Elena</author><author>Ozkes, Ali</author><author>Collaboration, Management Science Reproducibility</author></authors></contributors><titles><title>Reproducibility in Management Science</title></titles><dates><year>2024</year><pub-dates><date>2024-02-13</date></pub-dates></dates><electronic-resource-num>10.31219/osf.io/mydzv</electronic-resource-num><abstract>With the help of more than 700 reviewers we assess the reproducibility of nearly 500 articles published in the journal Management Science before and after the introduction of a new Data and Code Disclosure policy in 2019. When considering only articles for which data accessibility and hard- and software requirements were not an obstacle for reviewers, the results of more than 95% of articles under the new disclosure policy could be fully or largely computationally reproduced. However, for 29% of articles at least part of the dataset was not accessible to the reviewer. Considering all articles in our sample reduces the share of reproduced articles to 68%. These figures represent a significant increase compared to the period before the introduction of the disclosure policy, where only 12% of articles voluntarily provided replication materials, out of which 55% could be (largely) reproduced. Substantial heterogeneity in reproducibility rates across different fields is mainly driven by differences in dataset accessibility. Other reasons for unsuccessful reproduction attempts include missing code, unresolvable code errors, weak or missing documentation, but also soft- and hardware requirements and code complexity. Our findings highlight the importance of journal code and data disclosure policies, and suggest potential avenues for enhancing their effectiveness.</abstract><remote-database-name>osf.io</remote-database-name><language>en-us</language><urls><web-urls><url>https://osf.io/mydzv</url></web-urls></urls><access-date>2024-02-13 13:53:49</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Luijken, K.</author><author>Lohmann, A.</author><author>Alter, U.</author><author>Claramunt Gonzalez, J.</author><author>Clouth, F. J.</author><author>Fossum, J. L.</author><author>Hesen, L.</author><author>Huizing, A. H. J.</author><author>Ketelaar, J.</author><author>Montoya, A. K.</author><author>Nab, L.</author><author>Nijman, R. C. C.</author><author>Penning de Vries, B. B. L.</author><author>Tibbe, T. D.</author><author>Wang, Y. A.</author><author>Groenwold, R. H. H.</author></authors></contributors><titles><title>Replicability of simulation studies for the investigation of statistical methods: the RepliSims project</title><secondary-title>Royal Society Open Science</secondary-title><short-title>Replicability of simulation studies for the investigation of statistical methods</short-title></titles><periodical><full-title>Royal Society Open Science</full-title></periodical><pages>231003</pages><volume>11</volume><number>1</number><issue>1</issue><keywords><keyword>open materials</keyword><keyword>replication</keyword><keyword>simulation studies</keyword><keyword>statistical methods</keyword></keywords><dates><year>2024</year><pub-dates><date>2024-01-17</date></pub-dates></dates><electronic-resource-num>10.1098/rsos.231003</electronic-resource-num><abstract>Results of simulation studies evaluating the performance of statistical methods can have a major impact on the way empirical research is implemented. However, so far there is limited evidence of the replicability of simulation studies. Eight highly cited statistical simulation studies were selected, and their replicability was assessed by teams of replicators with formal training in quantitative methodology. The teams used information in the original publications to write simulation code with the aim of replicating the results. The primary outcome was to determine the feasibility of replicability based on reported information in the original publications and supplementary materials. Replicasility varied greatly: some original studies provided detailed information leading to almost perfect replication of results, whereas other studies did not provide enough information to implement any of the reported simulations. Factors facilitating replication included availability of code, detailed reporting or visualization of data-generating procedures and methods, and replicator expertise. Replicability of statistical simulation studies was mainly impeded by lack of information and sustainability of information sources. We encourage researchers publishing simulation studies to transparently report all relevant implementation details either in the research paper itself or in easily accessible supplementary material and to make their simulation code publicly available using permanent links.</abstract><remote-database-name>royalsocietypublishing.org (Atypon)</remote-database-name><urls><web-urls><url>https://royalsocietypublishing.org/doi/full/10.1098/rsos.231003</url></web-urls></urls><access-date>2024-02-13 13:33:36</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Arroyo-Araujo, María</author><author>Graf, Radka</author><author>Maco, Martine</author><author>van Dam, Elsbeth</author><author>Schenker, Esther</author><author>Drinkenburg, Wilhelmus</author><author>Koopmans, Bastijn</author><author>de Boer, Sietse F.</author><author>Cullum-Doyle, Michaela</author><author>Noldus, Lucas P. J. J.</author><author>Loos, Maarten</author><author>van Dommelen, Wil</author><author>Spooren, Will</author><author>Biemans, Barbara</author><author>Buhl, Derek L.</author><author>Kas, Martien J.</author></authors></contributors><titles><title>Reproducibility via coordinated standardization: a multi-center study in a Shank2 genetic rat model for Autism Spectrum Disorders</title><secondary-title>Scientific Reports</secondary-title><short-title>Reproducibility via coordinated standardization</short-title></titles><periodical><full-title>Scientific Reports</full-title><abbr-1>Sci Rep</abbr-1></periodical><pages>11602</pages><volume>9</volume><number>1</number><issue>1</issue><keywords><keyword>Autism spectrum disorders</keyword><keyword>Pharmacology</keyword></keywords><dates><year>2019</year><pub-dates><date>2019-08-12</date></pub-dates></dates><isbn>2045-2322</isbn><electronic-resource-num>10.1038/s41598-019-47981-0</electronic-resource-num><abstract>Inconsistent findings between laboratories are hampering scientific progress and are of increasing public concern. Differences in laboratory environment is a known factor contributing to poor reproducibility of findings between research sites, and well-controlled multisite efforts are an important next step to identify the relevant factors needed to reduce variation in study outcome between laboratories. Through harmonization of apparatus, test protocol, and aligned and non-aligned environmental variables, the present study shows that behavioral pharmacological responses in Shank2 knockout (KO) rats, a model of synaptic dysfunction relevant to autism spectrum disorders, were highly replicable across three research centers. All three sites reliably observed a hyperactive and repetitive behavioral phenotype in KO rats compared to their wild-type littermates as well as a dose-dependent phenotype attenuation following acute injections of a selective mGluR1 antagonist. These results show that reproducibility in preclinical studies can be obtained and emphasizes the need for high quality and rigorous methodologies in scientific research. Considering the observed external validity, the present study also suggests mGluR1 as potential target for the treatment of autism spectrum disorders.</abstract><remote-database-name>www.nature.com</remote-database-name><language>en</language><urls><web-urls><url>https://www.nature.com/articles/s41598-019-47981-0</url></web-urls></urls><access-date>2024-02-13 13:31:56</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Wang, Shirley V.</author><author>Sreedhara, Sushama Kattinakere</author><author>Schneeweiss, Sebastian</author><author>REPEAT Initiative</author><author>Franklin, Jessica M.</author><author>Gagne, Joshua J.</author><author>Huybrechts, Krista F.</author><author>Patorno, Elisabetta</author><author>Jin, Yinzhu</author><author>Lee, Moa</author><author>Mahesri, Mufaddal</author><author>Pawar, Ajinkya</author><author>Barberio, Julie</author><author>Bessette, Lily G.</author><author>Chin, Kristyn</author><author>Gautam, Nileesa</author><author>Ortiz, Adrian Santiago</author><author>Sears, Ellen</author><author>Stefanini, Kristina</author><author>Zakarian, Mimi</author><author>Dejene, Sara</author><author>Rogers, James R.</author><author>Brill, Gregory</author><author>Landon, Joan</author><author>Lii, Joyce</author><author>Tsacogianis, Theodore</author><author>Vine, Seanna</author><author>Garry, Elizabeth M.</author><author>Gibbs, Liza R.</author><author>Gierada, Monica</author><author>Isaman, Danielle L.</author><author>Payne, Emma</author><author>Alwardt, Sarah</author><author>Arlett, Peter</author><author>Bartels, Dorothee B.</author><author>Bate, Andrew</author><author>Berlin, Jesse</author><author>Bourke, Alison</author><author>Bradbury, Brian</author><author>Brown, Jeffrey</author><author>Burnett, Karen</author><author>Brennan, Troyen</author><author>Chan, K. Arnold</author><author>Choi, Nam-Kyong</author><author>De Vries, Frank</author><author>Eichler, Hans-Georg</author><author>Filion, Kristian B.</author><author>Freeman, Lisa</author><author>Hallas, Jesper</author><author>Happe, Laura</author><author>Hennessy, Sean</author><author>Jónsson, Páll</author><author>Ioannidis, John</author><author>Jimenez, Javier</author><author>Kahler, Kristijan H.</author><author>Laine, Christine</author><author>Loder, Elizabeth</author><author>Makady, Amr</author><author>Martin, David</author><author>Nguyen, Michael</author><author>Nosek, Brian</author><author>Platt, Richard</author><author>Platt, Robert W.</author><author>Seeger, John</author><author>Shrank, William</author><author>Smeeth, Liam</author><author>Sørensen, Henrik Toft</author><author>Tugwell, Peter</author><author>Uyama, Yoshiaki</author><author>Willke, Richard</author><author>Winkelmayer, Wolfgang</author><author>Zarin, Deborah</author></authors></contributors><titles><title>Reproducibility of real-world evidence studies using clinical practice data to inform regulatory and coverage decisions</title><secondary-title>Nature Communications</secondary-title></titles><periodical><full-title>Nature Communications</full-title><abbr-1>Nat Commun</abbr-1></periodical><pages>5126</pages><volume>13</volume><number>1</number><issue>1</issue><dates><year>2022</year><pub-dates><date>2022-08-31</date></pub-dates></dates><isbn>2041-1723</isbn><electronic-resource-num>10.1038/s41467-022-32310-3</electronic-resource-num><abstract>Abstract&#xD;            &#xD;              Studies that generate real-world evidence on the effects of medical products through analysis of digital data collected in clinical practice provide key insights for regulators, payers, and other healthcare decision-makers. Ensuring reproducibility of such findings is fundamental to effective evidence-based decision-making. We reproduce results for 150 studies published in peer-reviewed journals using the same healthcare databases as original investigators and evaluate the completeness of reporting for 250. Original and reproduction effect sizes were positively correlated (Pearson’s correlation = 0.85), a strong relationship with some room for improvement. The median and interquartile range for the relative magnitude of effect (e.g., hazard ratio&#xD;              original&#xD;              /hazard ratio&#xD;              reproduction&#xD;              ) is 1.0 [0.9, 1.1], range [0.3, 2.1]. While the majority of results are closely reproduced, a subset are not. The latter can be explained by incomplete reporting and updated data. Greater methodological transparency aligned with new guidance may further improve reproducibility and validity assessment, thus facilitating evidence-based decision-making. Study registration number: EUPAS19636.</abstract><remote-database-name>DOI.org (Crossref)</remote-database-name><language>en</language><urls><web-urls><url>https://www.nature.com/articles/s41467-022-32310-3</url></web-urls></urls><access-date>2024-02-13 13:25:27</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Breznau, Nate</author><author>Rinke, Eike Mark</author><author>Wuttke, Alexander</author><author>Nguyen, Hung H. V.</author><author>Adem, Muna</author><author>Adriaans, Jule</author><author>Alvarez-Benjumea, Amalia</author><author>Andersen, Henrik K.</author><author>Auer, Daniel</author><author>Azevedo, Flavio</author><author>Bahnsen, Oke</author><author>Balzer, Dave</author><author>Bauer, Gerrit</author><author>Bauer, Paul C.</author><author>Baumann, Markus</author><author>Baute, Sharon</author><author>Benoit, Verena</author><author>Bernauer, Julian</author><author>Berning, Carl</author><author>Berthold, Anna</author><author>Bethke, Felix S.</author><author>Biegert, Thomas</author><author>Blinzler, Katharina</author><author>Blumenberg, Johannes N.</author><author>Bobzien, Licia</author><author>Bohman, Andrea</author><author>Bol, Thijs</author><author>Bostic, Amie</author><author>Brzozowska, Zuzanna</author><author>Burgdorf, Katharina</author><author>Burger, Kaspar</author><author>Busch, Kathrin B.</author><author>Carlos-Castillo, Juan</author><author>Chan, Nathan</author><author>Christmann, Pablo</author><author>Connelly, Roxanne</author><author>Czymara, Christian S.</author><author>Damian, Elena</author><author>Ecker, Alejandro</author><author>Edelmann, Achim</author><author>Eger, Maureen A.</author><author>Ellerbrock, Simon</author><author>Forke, Anna</author><author>Forster, Andrea</author><author>Gaasendam, Chris</author><author>Gavras, Konstantin</author><author>Gayle, Vernon</author><author>Gessler, Theresa</author><author>Gnambs, Timo</author><author>Godefroidt, Amélie</author><author>Grömping, Max</author><author>Groß, Martin</author><author>Gruber, Stefan</author><author>Gummer, Tobias</author><author>Hadjar, Andreas</author><author>Heisig, Jan Paul</author><author>Hellmeier, Sebastian</author><author>Heyne, Stefanie</author><author>Hirsch, Magdalena</author><author>Hjerm, Mikael</author><author>Hochman, Oshrat</author><author>Hövermann, Andreas</author><author>Hunger, Sophia</author><author>Hunkler, Christian</author><author>Huth, Nora</author><author>Ignácz, Zsófia S.</author><author>Jacobs, Laura</author><author>Jacobsen, Jannes</author><author>Jaeger, Bastian</author><author>Jungkunz, Sebastian</author><author>Jungmann, Nils</author><author>Kauff, Mathias</author><author>Kleinert, Manuel</author><author>Klinger, Julia</author><author>Kolb, Jan-Philipp</author><author>Kołczyńska, Marta</author><author>Kuk, John</author><author>Kunißen, Katharina</author><author>Kurti Sinatra, Dafina</author><author>Langenkamp, Alexander</author><author>Lersch, Philipp M.</author><author>Löbel, Lea-Maria</author><author>Lutscher, Philipp</author><author>Mader, Matthias</author><author>Madia, Joan E.</author><author>Malancu, Natalia</author><author>Maldonado, Luis</author><author>Marahrens, Helge</author><author>Martin, Nicole</author><author>Martinez, Paul</author><author>Mayerl, Jochen</author><author>Mayorga, Oscar J.</author><author>McManus, Patricia</author><author>McWagner, Kyle</author><author>Meeusen, Cecil</author><author>Meierrieks, Daniel</author><author>Mellon, Jonathan</author><author>Merhout, Friedolin</author><author>Merk, Samuel</author><author>Meyer, Daniel</author><author>Micheli, Leticia</author><author>Mijs, Jonathan</author><author>Moya, Cristóbal</author><author>Neunhoeffer, Marcel</author><author>Nüst, Daniel</author><author>Nygård, Olav</author><author>Ochsenfeld, Fabian</author><author>Otte, Gunnar</author><author>Pechenkina, Anna O.</author><author>Prosser, Christopher</author><author>Raes, Louis</author><author>Ralston, Kevin</author><author>Ramos, Miguel R.</author><author>Roets, Arne</author><author>Rogers, Jonathan</author><author>Ropers, Guido</author><author>Samuel, Robin</author><author>Sand, Gregor</author><author>Schachter, Ariela</author><author>Schaeffer, Merlin</author><author>Schieferdecker, David</author><author>Schlueter, Elmar</author><author>Schmidt, Regine</author><author>Schmidt, Katja M.</author><author>Schmidt-Catran, Alexander</author><author>Schmiedeberg, Claudia</author><author>Schneider, Jürgen</author><author>Schoonvelde, Martijn</author><author>Schulte-Cloos, Julia</author><author>Schumann, Sandy</author><author>Schunck, Reinhard</author><author>Schupp, Jürgen</author><author>Seuring, Julian</author><author>Silber, Henning</author><author>Sleegers, Willem</author><author>Sonntag, Nico</author><author>Staudt, Alexander</author><author>Steiber, Nadia</author><author>Steiner, Nils</author><author>Sternberg, Sebastian</author><author>Stiers, Dieter</author><author>Stojmenovska, Dragana</author><author>Storz, Nora</author><author>Striessnig, Erich</author><author>Stroppe, Anne-Kathrin</author><author>Teltemann, Janna</author><author>Tibajev, Andrey</author><author>Tung, Brian</author><author>Vagni, Giacomo</author><author>Van Assche, Jasper</author><author>van der Linden, Meta</author><author>van der Noll, Jolanda</author><author>Van Hootegem, Arno</author><author>Vogtenhuber, Stefan</author><author>Voicu, Bogdan</author><author>Wagemans, Fieke</author><author>Wehl, Nadja</author><author>Werner, Hannah</author><author>Wiernik, Brenton M.</author><author>Winter, Fabian</author><author>Wolf, Christof</author><author>Yamada, Yuki</author><author>Zhang, Nan</author><author>Ziller, Conrad</author><author>Zins, Stefan</author><author>Żółtak, Tomasz</author></authors></contributors><titles><title>Observing many researchers using the same data and hypothesis reveals a hidden universe of uncertainty</title><secondary-title>Proceedings of the National Academy of Sciences</secondary-title></titles><periodical><full-title>Proceedings of the National Academy of Sciences</full-title></periodical><pages>e2203150119</pages><volume>119</volume><number>44</number><issue>44</issue><dates><year>2022</year><pub-dates><date>2022-11</date></pub-dates></dates><electronic-resource-num>10.1073/pnas.2203150119</electronic-resource-num><abstract>This study explores how researchers’ analytical choices affect the reliability of scientific findings. Most discussions of reliability problems in science focus on systematic biases. We broaden the lens to emphasize the idiosyncrasy of conscious and unconscious decisions that researchers make during data analysis. We coordinated 161 researchers in 73 research teams and observed their research decisions as they used the same data to independently test the same prominent social science hypothesis: that greater immigration reduces support for social policies among the public. In this typical case of social science research, research teams reported both widely diverging numerical findings and substantive conclusions despite identical start conditions. Researchers’ expertise, prior beliefs, and expectations barely predict the wide variation in research outcomes. More than 95% of the total variance in numerical results remains unexplained even after qualitative coding of all identifiable decisions in each team’s workflow. This reveals a universe of uncertainty that remains hidden when considering a single study in isolation. The idiosyncratic nature of how researchers’ results and conclusions varied is a previously underappreciated explanation for why many scientific hypotheses remain contested. These results call for greater epistemic humility and clarity in reporting scientific findings.</abstract><remote-database-name>pnas.org (Atypon)</remote-database-name><urls><web-urls><url>https://www.pnas.org/doi/10.1073/pnas.2203150119</url></web-urls></urls><access-date>2024-02-13 15:29:42</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Marcoci, Alexandru</author><author>Wilkinson, David Peter</author><author>Abatayo, Anna Lou</author><author>Baskin, Ernest</author><author>Berkman, Henk</author><author>Buchanan, Erin Michelle</author><author>Capitán, Sara</author><author>Capitán, Tabaré</author><author>Chan, Ginny</author><author>Cheng, Kent Jason Go</author><author>Coupe, Tom</author><author>Dryhurst, Sarah</author><author>Duan, Jane</author><author>Edlund, John</author><author>Errington, Timothy M.</author><author>Fedor, Anna</author><author>Fidler, Fiona</author><author>Field, James</author><author>Fox [SCORE, Nicholas</author><author>Fraser, Hannah</author><author>Freeman, Alexandra L. J.</author><author>Hanea, Anca</author><author>Holzmeister, Felix</author><author>Hong, Sanghyun</author><author>Huggins, Raquel</author><author>Huntington-Klein, Nick</author><author>Johannesson, Magnus</author><author>Jones, Angela</author><author>Kapoor, Hansika</author><author>Kerr, John R.</author><author>Struhl, Melissa Kline</author><author>Kolczynska, Marta</author><author>Liu, Yang</author><author>Loomas, Zachary</author><author>Luis [SCORE, Bri</author><author>Méndez, Esteban</author><author>Miske, Olivia</author><author>Nast, Carolin</author><author>Nosek, Brian A.</author><author>Parsons, Elan Simon</author><author>Pfeiffer, Thomas</author><author>Reed, W. Robert</author><author>Roozenbeek, Jon</author><author>Schlyfestone, Alexa R.</author><author>Schneider, Claudia R.</author><author>Soh, Andrew</author><author>Tagat, Anirudh</author><author>Tutor, Melba</author><author>Tyner, Andrew</author><author>Urbanska, Karolina</author><author>Linden, Dr Sander van der</author><author>Vercammen, Ans</author><author>Wintle, Bonnie</author></authors></contributors><titles><title>Predicting the replicability of social and behavioural science claims from the COVID-19 Preprint Replication Project with structured expert and novice groups</title></titles><dates><year>2024</year><pub-dates><date>2024-02-13</date></pub-dates></dates><electronic-resource-num>10.31222/osf.io/xdsjf</electronic-resource-num><abstract>Replication is an important “credibility control” mechanism for clarifying the reliability of published findings. However, replication is costly, and it is infeasible to replicate everything. Accurate, fast, lower cost alternatives such as eliciting predictions from experts or novices could accelerate credibility assessment and improve allocation of replication resources for important and uncertain findings. We elicited judgments from experts and novices on 100 claims from preprints about an emerging area of research (COVID-19 pandemic) using a new interactive structured elicitation protocol and we conducted 35 new replications. Participants’ average estimates were similar to the observed replication rate of 60%. After interacting with their peers, novices updated both their estimates and confidence in their judgements significantly more than experts and their accuracy improved more between elicitation rounds. Experts’ average accuracy was 0.54 (95% CI: [0.454, 0.628]) after interaction and they correctly classified 55% of claims; novices’ average accuracy was 0.55 (95% CI: [0.455, 0.628]), correctly classifying 61% of claims. The difference in accuracy between experts and novices was not significant and their judgments on the full set of claims were strongly correlated (r=.48). These results are consistent with prior investigations eliciting predictions about the replicability of published findings in established areas of research and suggest that expertise may not be required for credibility assessment of some research findings.</abstract><remote-database-name>osf.io</remote-database-name><language>en-us</language><urls><web-urls><url>https://osf.io/xdsjf</url></web-urls></urls><access-date>2024-02-13 13:49:39</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Kirkby, Robert</author></authors></contributors><titles><title>Quantitative Macroeconomics: Lessons Learned from Fourteen Replications</title><secondary-title>Computational Economics</secondary-title><short-title>Quantitative Macroeconomics</short-title></titles><periodical><full-title>Computational Economics</full-title><abbr-1>Comput Econ</abbr-1></periodical><pages>875-896</pages><volume>61</volume><number>2</number><issue>2</issue><dates><year>2023</year><pub-dates><date>2023-02-01</date></pub-dates></dates><isbn>1572-9974</isbn><electronic-resource-num>10.1007/s10614-022-10234-w</electronic-resource-num><abstract>I replicate all tables and figures from fourteen papers in Quantitative Macroeconomics, with an emphasis on incomplete market heterogeneous agent models. I report three main findings: (i) all (non-welfare related) major findings of the papers replicate, (ii) welfare findings based on linear approximation methods—1st-order perturbation, linear and log-linearization around steady-state, and linear-quadratic methods—should be treated as quantitatively suspect, (iii) decisions around methods for discretizing exogenous shocks have a large and unappreciated influence on results and should be prominently discussed in papers. While some smaller aspects of the papers do not replicate exactly, rather than nitpick in the body of this paper I instead describe some lessons learnt that may be useful for practitioners working with Quantitative Macroeconomic models. The replications use global methods allowing for non-linearities and I argue that these are important and need to be more widely used. I provide a checklist that researchers can use when trying to check that their work will be more easily reproducible. Matlab codes implementing the replications using the VFI Toolkit are provided, and full results of all replications are given in the online appendix. I conclude with three core points for best practice: (i) codes be made directly available (e.g., on github, not only ’on request’, and not just inside a zip file), (ii) report not just baseline parameters but also hyperparameters, equilibrium values, non-baseline parameters and initial conditions, and (iii) replication means rewriting codes from scratch, not just re-running available codes.</abstract><remote-database-name>Springer Link</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1007/s10614-022-10234-w</url></web-urls></urls><access-date>2024-02-11 18:14:22</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Klein, Richard A</author><author>Cook, Corey L.</author><author>Ebersole, Charles R.</author><author>Vitiello, Christine</author><author>Nosek, Brian A.</author><author>Hilgard, Joseph</author><author>Ahn, Paul Hangsan</author><author>Brady, Abbie J.</author><author>Chartier, Christopher R.</author><author>Christopherson, Cody D.</author><author>Clay, Samuel</author><author>Collisson, Brian</author><author>Crawford, Jarret T.</author><author>Cromar, Ryan</author><author>Gardiner, Gwendolyn</author><author>Gosnell, Courtney L.</author><author>Grahe, Jon</author><author>Hall, Calvin</author><author>Howard, Irene</author><author>Joy-Gaba, Jennifer A.</author><author>Kolb, Miranda</author><author>Legg, Angela M.</author><author>Levitan, Carmel A.</author><author>Mancini, Anthony D.</author><author>Manfredi, Dylan</author><author>Miller, Jason</author><author>Nave, Gideon</author><author>Redford, Liz</author><author>Schlitz, Ilaria</author><author>Schmidt, Kathleen</author><author>Skorinko, Jeanine L. M.</author><author>Storage, Daniel</author><author>Swanson, Trevor</author><author>Van Swol, Lyn M.</author><author>Vaughn, Leigh Ann</author><author>Vidamuerte, Devere</author><author>Wiggins, Brady</author><author>Ratliff, Kate A.</author></authors></contributors><titles><title>Many Labs 4: Failure to Replicate Mortality Salience Effect With and Without Original Author Involvement</title><secondary-title>Collabra: Psychology</secondary-title><short-title>Many Labs 4</short-title></titles><periodical><full-title>Collabra: Psychology</full-title><abbr-1>Collabra: Psychology</abbr-1></periodical><pages>35271</pages><volume>8</volume><number>1</number><issue>1</issue><dates><year>2022</year><pub-dates><date>2022-04-29</date></pub-dates></dates><isbn>2474-7394</isbn><electronic-resource-num>10.1525/collabra.35271</electronic-resource-num><abstract>Interpreting a failure to replicate is complicated by the fact that the failure could be due to the original finding being a false positive, unrecognized moderating influences between the original and replication procedures, or faulty implementation of the procedures in the replication. One strategy to maximize replication quality is involving the original authors in study design. We (N = 17 Labs and N = 1,550 participants, after exclusions) experimentally tested whether original author involvement improved replicability of a classic finding from Terror Management Theory (Greenberg et al., 1994). Our results were non-diagnostic of whether original author involvement improves replicability because we were unable to replicate the finding under any conditions. This suggests that the original finding was either a false positive or the conditions necessary to obtain it are not fully understood or no longer exist. Data, materials, analysis code, preregistration, and supplementary documents can be found on the OSF page: https://osf.io/8ccnw/</abstract><remote-database-name>Silverchair</remote-database-name><urls><web-urls><url>https://doi.org/10.1525/collabra.35271</url></web-urls></urls><access-date>2024-02-13 13:28:31</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Ebersole, Charles R.</author><author>Mathur, Maya B.</author><author>Baranski, Erica</author><author>Bart-Plange, Diane-Jo</author><author>Buttrick, Nicholas R.</author><author>Chartier, Christopher R.</author><author>Corker, Katherine S.</author><author>Corley, Martin</author><author>Hartshorne, Joshua K.</author><author>IJzerman, Hans</author><author>Lazarević, Ljiljana B.</author><author>Rabagliati, Hugh</author><author>Ropovik, Ivan</author><author>Aczel, Balazs</author><author>Aeschbach, Lena F.</author><author>Andrighetto, Luca</author><author>Arnal, Jack D.</author><author>Arrow, Holly</author><author>Babincak, Peter</author><author>Bakos, Bence E.</author><author>Baník, Gabriel</author><author>Baskin, Ernest</author><author>Belopavlović, Radomir</author><author>Bernstein, Michael H.</author><author>Białek, Michał</author><author>Bloxsom, Nicholas G.</author><author>Bodroža, Bojana</author><author>Bonfiglio, Diane B. V.</author><author>Boucher, Leanne</author><author>Brühlmann, Florian</author><author>Brumbaugh, Claudia C.</author><author>Casini, Erica</author><author>Chen, Yiling</author><author>Chiorri, Carlo</author><author>Chopik, William J.</author><author>Christ, Oliver</author><author>Ciunci, Antonia M.</author><author>Claypool, Heather M.</author><author>Coary, Sean</author><author>Čolić, Marija V.</author><author>Collins, W. Matthew</author><author>Curran, Paul G.</author><author>Day, Chris R.</author><author>Dering, Benjamin</author><author>Dreber, Anna</author><author>Edlund, John E.</author><author>Falcão, Filipe</author><author>Fedor, Anna</author><author>Feinberg, Lily</author><author>Ferguson, Ian R.</author><author>Ford, Máire</author><author>Frank, Michael C.</author><author>Fryberger, Emily</author><author>Garinther, Alexander</author><author>Gawryluk, Katarzyna</author><author>Ashbaugh, Kayla</author><author>Giacomantonio, Mauro</author><author>Giessner, Steffen R.</author><author>Grahe, Jon E.</author><author>Guadagno, Rosanna E.</author><author>Hałasa, Ewa</author><author>Hancock, Peter J. B.</author><author>Hilliard, Rias A.</author><author>Hüffmeier, Joachim</author><author>Hughes, Sean</author><author>Idzikowska, Katarzyna</author><author>Inzlicht, Michael</author><author>Jern, Alan</author><author>Jiménez-Leal, William</author><author>Johannesson, Magnus</author><author>Joy-Gaba, Jennifer A.</author><author>Kauff, Mathias</author><author>Kellier, Danielle J.</author><author>Kessinger, Grecia</author><author>Kidwell, Mallory C.</author><author>Kimbrough, Amanda M.</author><author>King, Josiah P. J.</author><author>Kolb, Vanessa S.</author><author>Kołodziej, Sabina</author><author>Kovacs, Marton</author><author>Krasuska, Karolina</author><author>Kraus, Sue</author><author>Krueger, Lacy E.</author><author>Kuchno, Katarzyna</author><author>Lage, Caio Ambrosio</author><author>Langford, Eleanor V.</author><author>Levitan, Carmel A.</author><author>de Lima, Tiago Jessé Souza</author><author>Lin, Hause</author><author>Lins, Samuel</author><author>Loy, Jia E.</author><author>Manfredi, Dylan</author><author>Markiewicz, Łukasz</author><author>Menon, Madhavi</author><author>Mercier, Brett</author><author>Metzger, Mitchell</author><author>Meyet, Venus</author><author>Millen, Ailsa E.</author><author>Miller, Jeremy K.</author><author>Montealegre, Andres</author><author>Moore, Don A.</author><author>Muda, Rafał</author><author>Nave, Gideon</author><author>Nichols, Austin Lee</author><author>Novak, Sarah A.</author><author>Nunnally, Christian</author><author>Orlić, Ana</author><author>Palinkas, Anna</author><author>Panno, Angelo</author><author>Parks, Kimberly P.</author><author>Pedović, Ivana</author><author>Pękala, Emilian</author><author>Penner, Matthew R.</author><author>Pessers, Sebastiaan</author><author>Petrović, Boban</author><author>Pfeiffer, Thomas</author><author>Pieńkosz, Damian</author><author>Preti, Emanuele</author><author>Purić, Danka</author><author>Ramos, Tiago</author><author>Ravid, Jonathan</author><author>Razza, Timothy S.</author><author>Rentzsch, Katrin</author><author>Richetin, Juliette</author><author>Rife, Sean C.</author><author>Rosa, Anna Dalla</author><author>Rudy, Kaylis Hase</author><author>Salamon, Janos</author><author>Saunders, Blair</author><author>Sawicki, Przemysław</author><author>Schmidt, Kathleen</author><author>Schuepfer, Kurt</author><author>Schultze, Thomas</author><author>Schulz-Hardt, Stefan</author><author>Schütz, Astrid</author><author>Shabazian, Ani N.</author><author>Shubella, Rachel L.</author><author>Siegel, Adam</author><author>Silva, Rúben</author><author>Sioma, Barbara</author><author>Skorb, Lauren</author><author>de Souza, Luana Elayne Cunha</author><author>Steegen, Sara</author><author>Stein, L. A. R.</author><author>Sternglanz, R. Weylin</author><author>Stojilović, Darko</author><author>Storage, Daniel</author><author>Sullivan, Gavin Brent</author><author>Szaszi, Barnabas</author><author>Szecsi, Peter</author><author>Szöke, Orsolya</author><author>Szuts, Attila</author><author>Thomae, Manuela</author><author>Tidwell, Natasha D.</author><author>Tocco, Carly</author><author>Torka, Ann-Kathrin</author><author>Tuerlinckx, Francis</author><author>Vanpaemel, Wolf</author><author>Vaughn, Leigh Ann</author><author>Vianello, Michelangelo</author><author>Viganola, Domenico</author><author>Vlachou, Maria</author><author>Walker, Ryan J.</author><author>Weissgerber, Sophia C.</author><author>Wichman, Aaron L.</author><author>Wiggins, Bradford J.</author><author>Wolf, Daniel</author><author>Wood, Michael J.</author><author>Zealley, David</author><author>Žeželj, Iris</author><author>Zrubka, Mark</author><author>Nosek, Brian A.</author></authors></contributors><titles><title>Many Labs 5: Testing Pre-Data-Collection Peer Review as an Intervention to Increase Replicability</title><secondary-title>Advances in Methods and Practices in Psychological Science</secondary-title><short-title>Many Labs 5</short-title></titles><periodical><full-title>Advances in Methods and Practices in Psychological Science</full-title></periodical><pages>309-331</pages><volume>3</volume><number>3</number><issue>3</issue><dates><year>2020</year><pub-dates><date>2020-09-01</date></pub-dates></dates><isbn>2515-2459</isbn><electronic-resource-num>10.1177/2515245920958687</electronic-resource-num><abstract>Replication studies in psychological science sometimes fail to reproduce prior findings. If these studies use methods that are unfaithful to the original study or ineffective in eliciting the phenomenon of interest, then a failure to replicate may be a failure of the protocol rather than a challenge to the original finding. Formal pre-data-collection peer review by experts may address shortcomings and increase replicability rates. We selected 10 replication studies from the Reproducibility Project: Psychology (RP:P; Open Science Collaboration, 2015) for which the original authors had expressed concerns about the replication designs before data collection; only one of these studies had yielded a statistically significant effect (p &lt; .05). Commenters suggested that lack of adherence to expert review and low-powered tests were the reasons that most of these RP:P studies failed to replicate the original effects. We revised the replication protocols and received formal peer review prior to conducting new replication studies. We administered the RP:P and revised protocols in multiple laboratories (median number of laboratories per original study = 6.5, range = 3–9; median total sample = 1,279.5, range = 276–3,512) for high-powered tests of each original finding with both protocols. Overall, following the preregistered analysis plan, we found that the revised protocols produced effect sizes similar to those of the RP:P protocols (Δr = .002 or .014, depending on analytic approach). The median effect size for the revised protocols (r = .05) was similar to that of the RP:P protocols (r = .04) and the original RP:P replications (r = .11), and smaller than that of the original studies (r = .37). Analysis of the cumulative evidence across the original studies and the corresponding three replication attempts provided very precise estimates of the 10 tested effects and indicated that their effect sizes (median r = .07, range = .00–.15) were 78% smaller, on average, than the original effect sizes (median r = .37, range = .19–.50).</abstract><remote-database-name>SAGE Journals</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1177/2515245920958687</url></web-urls></urls><access-date>2024-02-13 13:30:28</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Ebersole, Charles R.</author><author>Atherton, Olivia E.</author><author>Belanger, Aimee L.</author><author>Skulborstad, Hayley M.</author><author>Allen, Jill M.</author><author>Banks, Jonathan B.</author><author>Baranski, Erica</author><author>Bernstein, Michael J.</author><author>Bonfiglio, Diane B. V.</author><author>Boucher, Leanne</author><author>Brown, Elizabeth R.</author><author>Budiman, Nancy I.</author><author>Cairo, Athena H.</author><author>Capaldi, Colin A.</author><author>Chartier, Christopher R.</author><author>Chung, Joanne M.</author><author>Cicero, David C.</author><author>Coleman, Jennifer A.</author><author>Conway, John G.</author><author>Davis, William E.</author><author>Devos, Thierry</author><author>Fletcher, Melody M.</author><author>German, Komi</author><author>Grahe, Jon E.</author><author>Hermann, Anthony D.</author><author>Hicks, Joshua A.</author><author>Honeycutt, Nathan</author><author>Humphrey, Brandon</author><author>Janus, Matthew</author><author>Johnson, David J.</author><author>Joy-Gaba, Jennifer A.</author><author>Juzeler, Hannah</author><author>Keres, Ashley</author><author>Kinney, Diana</author><author>Kirshenbaum, Jacqeline</author><author>Klein, Richard A.</author><author>Lucas, Richard E.</author><author>Lustgraaf, Christopher J. N.</author><author>Martin, Daniel</author><author>Menon, Madhavi</author><author>Metzger, Mitchell</author><author>Moloney, Jaclyn M.</author><author>Morse, Patrick J.</author><author>Prislin, Radmila</author><author>Razza, Timothy</author><author>Re, Daniel E.</author><author>Rule, Nicholas O.</author><author>Sacco, Donald F.</author><author>Sauerberger, Kyle</author><author>Shrider, Emily</author><author>Shultz, Megan</author><author>Siemsen, Courtney</author><author>Sobocko, Karin</author><author>Weylin Sternglanz, R.</author><author>Summerville, Amy</author><author>Tskhay, Konstantin O.</author><author>van Allen, Zack</author><author>Vaughn, Leigh Ann</author><author>Walker, Ryan J.</author><author>Weinberg, Ashley</author><author>Wilson, John Paul</author><author>Wirth, James H.</author><author>Wortman, Jessica</author><author>Nosek, Brian A.</author></authors></contributors><titles><title>Many Labs 3: Evaluating participant pool quality across the academic semester via replication</title><secondary-title>Journal of Experimental Social Psychology</secondary-title><short-title>Many Labs 3</short-title></titles><periodical><full-title>Journal of Experimental Social Psychology</full-title><abbr-1>Journal of Experimental Social Psychology</abbr-1></periodical><pages>68-82</pages><volume>67</volume><keywords><keyword>Cognitive psychology</keyword><keyword>Individual differences</keyword><keyword>Participant pool</keyword><keyword>Replication</keyword><keyword>Sampling effects</keyword><keyword>Situational effects</keyword><keyword>Social psychology</keyword></keywords><dates><year>2016</year><pub-dates><date>2016-11-01</date></pub-dates></dates><isbn>0022-1031</isbn><electronic-resource-num>10.1016/j.jesp.2015.10.012</electronic-resource-num><abstract>The university participant pool is a key resource for behavioral research, and data quality is believed to vary over the course of the academic semester. This crowdsourced project examined time of semester variation in 10 known effects, 10 individual differences, and 3 data quality indicators over the course of the academic semester in 20 participant pools (N=2696) and with an online sample (N=737). Weak time of semester effects were observed on data quality indicators, participant sex, and a few individual differences—conscientiousness, mood, and stress. However, there was little evidence for time of semester qualifying experimental or correlational effects. The generality of this evidence is unknown because only a subset of the tested effects demonstrated evidence for the original result in the whole sample. Mean characteristics of pool samples change slightly during the semester, but these data suggest that those changes are mostly irrelevant for detecting effects.</abstract><remote-database-name>ScienceDirect</remote-database-name><urls><web-urls><url>https://www.sciencedirect.com/science/article/pii/S0022103115300123</url></web-urls></urls><access-date>2024-02-13 13:27:26</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Web Page">12</ref-type><contributors><authors><author>Chang, J.-Y. A.</author><author>Chilcott, J. B.</author><author>Latimer, N. R.</author></authors></contributors><titles><title>Leveraging real-world data to assess treatment sequences in health economic evaluations: a study protocol for emulating target trials using the English Cancer Registry and US Electronic Health Records-Derived Database</title><secondary-title>HEDS Discussion Paper</secondary-title><short-title>Leveraging real-world data to assess treatment sequences in health economic evaluations</short-title></titles><periodical><full-title>HEDS Discussion Paper</full-title></periodical><dates><year>2024</year><pub-dates><date>2024-01-26</date></pub-dates></dates><abstract>Background&#xD;&#xD;Considering the sequence of treatments is vital for optimising healthcare resource allocation, especially in cancer care, where sequence changes can affect patients’ overall survival and associated costs. A key challenge in evaluating treatment sequences in health technology assessments (HTA) is the scarce evidence on effectiveness, leading to uncertainties in decision making. While randomised controlled trials (RCTs) and meta-analyses are viewed as the gold standards for evidence, applying&#xD;them to determine the effectiveness of treatment sequences in economic models often necessitates making arbitrary assumptions due to insufficient information on patients' treatment histories and&#xD;subsequent therapies. In contrast, real-world data (RWD) presents a promising alternative source of evidence, often encompassing details across treatment lines. However, due to its non-randomised&#xD;nature, estimates of the treatment effectiveness based on RWD analyses can be susceptible to biases if not properly adjusted for confounding factors. To date, several international initiatives have been investigating methods to derive reliable treatment effects from RWD — by emulating Target Trials that replicate existing RCTs (i.e. benchmarks) and comparing the emulated results against the benchmarks. These studies primarily seek to determine the viability of obtaining trial-equivalent results through deploying specific &#xD;analytical methodologies and study designs within the Target Trial emulation framework, using a given database. Adopting the Target Trial emulation framework facilitates the analyses to be operated&#xD;under causal inference principles. Upon validation in a particular database, these techniques can be applied to address similar questions (e.g., same disease area, same outcome type), but in populations lacking clinical trial evidence, leveraging the same RWD source. Studies to date, however, have predominantly focused on the comparison of individual treatments rather than treatment sequences. Moreover, the majority of these investigations have been undertaken in non-English contexts. Consequently, the use of RWD in evaluating treatment sequences for HTA, especially in an English setting, remains largely unexplored.&#xD;&#xD;Objectives&#xD;&#xD;The goal of this project is to investigate the feasibility of leveraging RWD to produce reliable, trial-like effectiveness estimates for treatment sequences. We aim to assess the capability of two&#xD;oncology databases: the US-based Flatiron electronic health record and the National Cancer Registration and Analysis Service (NCRAS) database of England. To achieve this, we plan to harness the Target Trial Emulation (TTE) framework for replicating two existing  oncology RCTs that compared treatment sequences, with the intent of benchmarking our results against the original studies. Further, we aim to detail the practicalities involved with implementing TTE in diverse databases and outline the challenges encountered.&#xD;&#xD;Methods&#xD;&#xD;1. We aim to emulate existing RCTs that compare the effect of different treatment sequences by constructing the study design and analysis plan following the TTE framework. Specifically, the&#xD;following case studies are planned:&#xD;(1) Prostate cancer case study 1 (PC1) - US direct proof-of-concept study (method direct validation): replicating the GUTG-001 trial using Flatiron data&#xD;(2) Prostate cancer case study 2 (PC2) - US-England bridging study (method extension): emulating Target Trials that compare treatment sequences that have been common in England using Flatiron data&#xD;(3) Prostate cancer case study 3 (PC3) - English indirect proof-of-concept study (method indirect validation): emulating the same Target Trial in PC2 using English NCRAS data&#xD;(4) Renal cell carcinoma case study (RCC) - method direct validation in a single-arm setting: emulating the sunitinib followed by everolimus arm in the RECORD-3 trial using English NCRAS data&#xD;2. We will compare results of the emulated Target Trials with those from the benchmark trials.&#xD;3. We plan to compare different advanced causal inference methods (e.g. marginal structural models using IPW and other g-methods) in estimating the effect of treatment sequences in RWD.&#xD;&#xD;Expected results&#xD;&#xD;This study will provide evidence on whether it is feasible to obtain reliable estimates of the (comparative) effectiveness of treatment sequences using Flatiron data and English NCRAS data. If applicable, we intend to develop a framework that provides a systematic way of obtaining the (comparative) effectiveness of treatment sequences using RWD. It is possible that the data quality is insufficient to emulate the planned Target Trials. In this case, we will report reasons for the implausibility of data analysis. If  applicable, we will make suggestions to whether the national health&#xD;data collection may be enhanced to make the analyses possible. The results of this study will be submitted to peer-reviewed journals and international conferences.</abstract><work-type>Monograph</work-type><language>en</language><urls><web-urls><url>https://eprints.whiterose.ac.uk/208318/</url></web-urls></urls><access-date>2024-02-13 13:36:27</access-date><misc2>Monograph</misc2></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Klein, Richard A.</author><author>Vianello, Michelangelo</author><author>Hasselman, Fred</author><author>Adams, Byron G.</author><author>Adams, Reginald B.</author><author>Alper, Sinan</author><author>Aveyard, Mark</author><author>Axt, Jordan R.</author><author>Babalola, Mayowa T.</author><author>Bahník, Štěpán</author><author>Batra, Rishtee</author><author>Berkics, Mihály</author><author>Bernstein, Michael J.</author><author>Berry, Daniel R.</author><author>Bialobrzeska, Olga</author><author>Binan, Evans Dami</author><author>Bocian, Konrad</author><author>Brandt, Mark J.</author><author>Busching, Robert</author><author>Rédei, Anna Cabak</author><author>Cai, Huajian</author><author>Cambier, Fanny</author><author>Cantarero, Katarzyna</author><author>Carmichael, Cheryl L.</author><author>Ceric, Francisco</author><author>Chandler, Jesse</author><author>Chang, Jen-Ho</author><author>Chatard, Armand</author><author>Chen, Eva E.</author><author>Cheong, Winnee</author><author>Cicero, David C.</author><author>Coen, Sharon</author><author>Coleman, Jennifer A.</author><author>Collisson, Brian</author><author>Conway, Morgan A.</author><author>Corker, Katherine S.</author><author>Curran, Paul G.</author><author>Cushman, Fiery</author><author>Dagona, Zubairu K.</author><author>Dalgar, Ilker</author><author>Dalla Rosa, Anna</author><author>Davis, William E.</author><author>de Bruijn, Maaike</author><author>De Schutter, Leander</author><author>Devos, Thierry</author><author>de Vries, Marieke</author><author>Doğulu, Canay</author><author>Dozo, Nerisa</author><author>Dukes, Kristin Nicole</author><author>Dunham, Yarrow</author><author>Durrheim, Kevin</author><author>Ebersole, Charles R.</author><author>Edlund, John E.</author><author>Eller, Anja</author><author>English, Alexander Scott</author><author>Finck, Carolyn</author><author>Frankowska, Natalia</author><author>Freyre, Miguel-Ángel</author><author>Friedman, Mike</author><author>Galliani, Elisa Maria</author><author>Gandi, Joshua C.</author><author>Ghoshal, Tanuka</author><author>Giessner, Steffen R.</author><author>Gill, Tripat</author><author>Gnambs, Timo</author><author>Gómez, Ángel</author><author>González, Roberto</author><author>Graham, Jesse</author><author>Grahe, Jon E.</author><author>Grahek, Ivan</author><author>Green, Eva G. T.</author><author>Hai, Kakul</author><author>Haigh, Matthew</author><author>Haines, Elizabeth L.</author><author>Hall, Michael P.</author><author>Heffernan, Marie E.</author><author>Hicks, Joshua A.</author><author>Houdek, Petr</author><author>Huntsinger, Jeffrey R.</author><author>Huynh, Ho Phi</author><author>IJzerman, Hans</author><author>Inbar, Yoel</author><author>Innes-Ker, Åse H.</author><author>Jiménez-Leal, William</author><author>John, Melissa-Sue</author><author>Joy-Gaba, Jennifer A.</author><author>Kamiloğlu, Roza G.</author><author>Kappes, Heather Barry</author><author>Karabati, Serdar</author><author>Karick, Haruna</author><author>Keller, Victor N.</author><author>Kende, Anna</author><author>Kervyn, Nicolas</author><author>Knežević, Goran</author><author>Kovacs, Carrie</author><author>Krueger, Lacy E.</author><author>Kurapov, German</author><author>Kurtz, Jamie</author><author>Lakens, Daniël</author><author>Lazarević, Ljiljana B.</author><author>Levitan, Carmel A.</author><author>Lewis, Neil A.</author><author>Lins, Samuel</author><author>Lipsey, Nikolette P.</author><author>Losee, Joy E.</author><author>Maassen, Esther</author><author>Maitner, Angela T.</author><author>Malingumu, Winfrida</author><author>Mallett, Robyn K.</author><author>Marotta, Satia A.</author><author>Međedović, Janko</author><author>Mena-Pacheco, Fernando</author><author>Milfont, Taciano L.</author><author>Morris, Wendy L.</author><author>Murphy, Sean C.</author><author>Myachykov, Andriy</author><author>Neave, Nick</author><author>Neijenhuijs, Koen</author><author>Nelson, Anthony J.</author><author>Neto, Félix</author><author>Lee Nichols, Austin</author><author>Ocampo, Aaron</author><author>O’Donnell, Susan L.</author><author>Oikawa, Haruka</author><author>Oikawa, Masanori</author><author>Ong, Elsie</author><author>Orosz, Gábor</author><author>Osowiecka, Malgorzata</author><author>Packard, Grant</author><author>Pérez-Sánchez, Rolando</author><author>Petrović, Boban</author><author>Pilati, Ronaldo</author><author>Pinter, Brad</author><author>Podesta, Lysandra</author><author>Pogge, Gabrielle</author><author>Pollmann, Monique M. H.</author><author>Rutchick, Abraham M.</author><author>Saavedra, Patricio</author><author>Saeri, Alexander K.</author><author>Salomon, Erika</author><author>Schmidt, Kathleen</author><author>Schönbrodt, Felix D.</author><author>Sekerdej, Maciej B.</author><author>Sirlopú, David</author><author>Skorinko, Jeanine L. M.</author><author>Smith, Michael A.</author><author>Smith-Castro, Vanessa</author><author>Smolders, Karin C. H. J.</author><author>Sobkow, Agata</author><author>Sowden, Walter</author><author>Spachtholz, Philipp</author><author>Srivastava, Manini</author><author>Steiner, Troy G.</author><author>Stouten, Jeroen</author><author>Street, Chris N. H.</author><author>Sundfelt, Oskar K.</author><author>Szeto, Stephanie</author><author>Szumowska, Ewa</author><author>Tang, Andrew C. W.</author><author>Tanzer, Norbert</author><author>Tear, Morgan J.</author><author>Theriault, Jordan</author><author>Thomae, Manuela</author><author>Torres, David</author><author>Traczyk, Jakub</author><author>Tybur, Joshua M.</author><author>Ujhelyi, Adrienn</author><author>van Aert, Robbie C. M.</author><author>van Assen, Marcel A. L. M.</author><author>van der Hulst, Marije</author><author>van Lange, Paul A. M.</author><author>van ’t Veer, Anna Elisabeth</author><author>Vásquez- Echeverría, Alejandro</author><author>Ann Vaughn, Leigh</author><author>Vázquez, Alexandra</author><author>Vega, Luis Diego</author><author>Verniers, Catherine</author><author>Verschoor, Mark</author><author>Voermans, Ingrid P. J.</author><author>Vranka, Marek A.</author><author>Welch, Cheryl</author><author>Wichman, Aaron L.</author><author>Williams, Lisa A.</author><author>Wood, Michael</author><author>Woodzicka, Julie A.</author><author>Wronska, Marta K.</author><author>Young, Liane</author><author>Zelenski, John M.</author><author>Zhijia, Zeng</author><author>Nosek, Brian A.</author></authors></contributors><titles><title>Many Labs 2: Investigating Variation in Replicability Across Samples and Settings</title><secondary-title>Advances in Methods and Practices in Psychological Science</secondary-title><short-title>Many Labs 2</short-title></titles><periodical><full-title>Advances in Methods and Practices in Psychological Science</full-title></periodical><pages>443-490</pages><volume>1</volume><number>4</number><issue>4</issue><dates><year>2018</year><pub-dates><date>2018-12-01</date></pub-dates></dates><isbn>2515-2459</isbn><electronic-resource-num>10.1177/2515245918810225</electronic-resource-num><abstract>We conducted preregistered replications of 28 classic and contemporary published findings, with protocols that were peer reviewed in advance, to examine variation in effect magnitudes across samples and settings. Each protocol was administered to approximately half of 125 samples that comprised 15,305 participants from 36 countries and territories. Using the conventional criterion of statistical significance (p &lt; .05), we found that 15 (54%) of the replications provided evidence of a statistically significant effect in the same direction as the original finding. With a strict significance criterion (p &lt; .0001), 14 (50%) of the replications still provided such evidence, a reflection of the extremely high-powered design. Seven (25%) of the replications yielded effect sizes larger than the original ones, and 21 (75%) yielded effect sizes smaller than the original ones. The median comparable Cohen’s ds were 0.60 for the original findings and 0.15 for the replications. The effect sizes were small (&lt; 0.20) in 16 of the replications (57%), and 9 effects (32%) were in the direction opposite the direction of the original effect. Across settings, the Q statistic indicated significant heterogeneity in 11 (39%) of the replication effects, and most of those were among the findings with the largest overall effect sizes; only 1 effect that was near zero in the aggregate showed significant heterogeneity according to this measure. Only 1 effect had a tau value greater than .20, an indication of moderate heterogeneity. Eight others had tau values near or slightly above .10, an indication of slight heterogeneity. Moderation tests indicated that very little heterogeneity was attributable to the order in which the tasks were performed or whether the tasks were administered in lab versus online. Exploratory comparisons revealed little heterogeneity between Western, educated, industrialized, rich, and democratic (WEIRD) cultures and less WEIRD cultures (i.e., cultures with relatively high and low WEIRDness scores, respectively). Cumulatively, variability in the observed effect sizes was attributable more to the effect being studied than to the sample or setting in which it was studied.</abstract><remote-database-name>SAGE Journals</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1177/2515245918810225</url></web-urls></urls><access-date>2024-02-13 13:26:56</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Irvine, Krin</author><author>Hoffman, David A.</author><author>Wilkinson-Ryan, Tess</author></authors></contributors><titles><title>Law and Psychology Grows Up, Goes Online, and Replicates</title><secondary-title>Journal of Empirical Legal Studies</secondary-title></titles><periodical><full-title>Journal of Empirical Legal Studies</full-title></periodical><pages>320-355</pages><volume>15</volume><number>2</number><issue>2</issue><dates><year>2018</year><pub-dates><date>2018</date></pub-dates></dates><isbn>1740-1461</isbn><electronic-resource-num>10.1111/jels.12180</electronic-resource-num><abstract>Over the last 30 years, legal scholars have increasingly deployed experimental studies, particularly hypothetical scenarios, to test intuitions about legal reasoning and behavior. That movement has accelerated in the last decade, facilitated in large part by cheap and convenient Internet participant recruiting platforms like Amazon Mechanical Turk. The widespread use of online subjects, a practice that dramatically lowers the barriers to entry for experimental research, has been controversial. At the same time, the field of experimental psychology is experiencing a public crisis of confidence widely discussed in terms of the “replication crisis.” At present, law and psychology research is arguably in a new era, in which it is both an accepted feature of the legal landscape and also a target of fresh skepticism. The moment is ripe for taking stock. In this article, we bring an empirical approach to these problems. Using three canonical law and psychology findings, we document the challenges and the feasibility of reproducing results across platforms. We evaluate the extent to which we are able to reproduce the original findings with contemporary subject pools (Amazon Mechanical Turk, other national online platforms, and in-person labs). We partially replicate all three results, and show marked similarities in subject responses across platforms. In the context of the experiments here, we conclude that meaningful replication requires active intervention in order to keep the materials relevant and sensible. The second aim is to compare Amazon Mechanical Turk subjects to the original samples and to the replication samples. We find, consistent with the weight of recent evidence, that the Amazon Mechanical Turk samples are reasonably appropriate for these kinds of scenario studies. Subjects are highly similar to subjects on other online platforms and in-person samples, though they differ in their high level of attentiveness. Finally, we review the growing replication literature across disciplines, as well as our firsthand experience, to propose a set of standard practices for the publication of results in law and psychology.</abstract><remote-database-name>Wiley Online Library</remote-database-name><language>en</language><urls><web-urls><url>https://onlinelibrary.wiley.com/doi/abs/10.1111/jels.12180</url></web-urls></urls><access-date>2024-02-11 18:02:38</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>C. Chang, Andrew</author><author>Li, Phillip</author></authors></contributors><titles><title>Is Economics Research Replicable? Sixty Published Papers From Thirteen Journals Say “Often Not”</title><secondary-title>Critical Finance Review</secondary-title><short-title>Is Economics Research Replicable?</short-title></titles><periodical><full-title>Critical Finance Review</full-title><abbr-1>CFR</abbr-1></periodical><pages>185-206</pages><volume>11</volume><number>1</number><issue>1</issue><dates><year>2022</year><pub-dates><date>2022</date></pub-dates></dates><isbn>2164-5744, 2164-5760</isbn><electronic-resource-num>10.1561/104.00000053</electronic-resource-num><remote-database-name>DOI.org (Crossref)</remote-database-name><language>en</language><urls><web-urls><url>http://www.nowpublishers.com/article/Details/CFR-0053</url></web-urls></urls><access-date>2024-02-11 17:57:04</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Balli, Hatice Ozer</author><author>Sørensen, Bent E.</author></authors></contributors><titles><title>Interaction effects in econometrics</title><secondary-title>Empirical Economics</secondary-title></titles><periodical><full-title>Empirical Economics</full-title><abbr-1>Empir Econ</abbr-1></periodical><pages>583-603</pages><volume>45</volume><number>1</number><issue>1</issue><keywords><keyword>C12</keyword><keyword>C13</keyword><keyword>Interaction terms</keyword><keyword>Non-linear regression</keyword></keywords><dates><year>2013</year><pub-dates><date>2013-08-01</date></pub-dates></dates><isbn>1435-8921</isbn><electronic-resource-num>10.1007/s00181-012-0604-2</electronic-resource-num><abstract>We provide practical advice for applied economists regarding robust specification and interpretation of linear regression models with interaction terms. We replicate a number of prominently published results using interaction effects and examine if they are robust to reasonable specification permutations.</abstract><remote-database-name>Springer Link</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1007/s00181-012-0604-2</url></web-urls></urls><access-date>2024-02-13 13:38:36</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Soto, Christopher J.</author></authors></contributors><titles><title>How Replicable Are Links Between Personality Traits and Consequential Life Outcomes? The Life Outcomes of Personality Replication Project</title><secondary-title>Psychological Science</secondary-title><short-title>How Replicable Are Links Between Personality Traits and Consequential Life Outcomes?</short-title></titles><periodical><full-title>Psychological Science</full-title><abbr-1>Psychol Sci</abbr-1></periodical><pages>711-727</pages><volume>30</volume><number>5</number><issue>5</issue><dates><year>2019</year><pub-dates><date>2019-05-01</date></pub-dates></dates><isbn>0956-7976</isbn><electronic-resource-num>10.1177/0956797619831612</electronic-resource-num><abstract>The Big Five personality traits have been linked to dozens of life outcomes. However, metascientific research has raised questions about the replicability of behavioral science. The Life Outcomes of Personality Replication (LOOPR) Project was therefore conducted to estimate the replicability of the personality-outcome literature. Specifically, I conducted preregistered, high-powered (median N = 1,504) replications of 78 previously published trait–outcome associations. Overall, 87% of the replication attempts were statistically significant in the expected direction. The replication effects were typically 77% as strong as the corresponding original effects, which represents a significant decline in effect size. The replicability of individual effects was predicted by the effect size and design of the original study, as well as the sample size and statistical power of the replication. These results indicate that the personality-outcome literature provides a reasonably accurate map of trait–outcome associations but also that it stands to benefit from efforts to improve replicability.</abstract><remote-database-name>SAGE Journals</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1177/0956797619831612</url></web-urls></urls><access-date>2024-02-13 13:32:42</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Klein, Richard A.</author><author>Ratliff, Kate A.</author><author>Vianello, Michelangelo</author><author>Adams, Reginald B.</author><author>Bahník, Štěpán</author><author>Bernstein, Michael J.</author><author>Bocian, Konrad</author><author>Brandt, Mark J.</author><author>Brooks, Beach</author><author>Brumbaugh, Claudia Chloe</author><author>Cemalcilar, Zeynep</author><author>Chandler, Jesse</author><author>Cheong, Winnee</author><author>Davis, William E.</author><author>Devos, Thierry</author><author>Eisner, Matthew</author><author>Frankowska, Natalia</author><author>Furrow, David</author><author>Galliani, Elisa Maria</author><author>Hasselman, Fred</author><author>Hicks, Joshua A.</author><author>Hovermale, James F.</author><author>Hunt, S. Jane</author><author>Huntsinger, Jeffrey R.</author><author>IJzerman, Hans</author><author>John, Melissa-Sue</author><author>Joy-Gaba, Jennifer A.</author><author>Barry Kappes, Heather</author><author>Krueger, Lacy E.</author><author>Kurtz, Jaime</author><author>Levitan, Carmel A.</author><author>Mallett, Robyn K.</author><author>Morris, Wendy L.</author><author>Nelson, Anthony J.</author><author>Nier, Jason A.</author><author>Packard, Grant</author><author>Pilati, Ronaldo</author><author>Rutchick, Abraham M.</author><author>Schmidt, Kathleen</author><author>Skorinko, Jeanine L.</author><author>Smith, Robert</author><author>Steiner, Troy G.</author><author>Storbeck, Justin</author><author>Van Swol, Lyn M.</author><author>Thompson, Donna</author><author>van ‘t Veer, A. E.</author><author>Ann Vaughn, Leigh</author><author>Vranka, Marek</author><author>Wichman, Aaron L.</author><author>Woodzicka, Julie A.</author><author>Nosek, Brian A.</author></authors></contributors><titles><title>Investigating Variation in Replicability</title><secondary-title>Social Psychology</secondary-title></titles><periodical><full-title>Social Psychology</full-title></periodical><pages>142-152</pages><volume>45</volume><number>3</number><issue>3</issue><keywords><keyword>cross-cultural</keyword><keyword>generalizability</keyword><keyword>replication</keyword><keyword>reproducibility</keyword><keyword>variation</keyword></keywords><dates><year>2014</year><pub-dates><date>2014-05</date></pub-dates></dates><isbn>1864-9335</isbn><electronic-resource-num>10.1027/1864-9335/a000178</electronic-resource-num><abstract>Although replication is a central tenet of science, direct replications are rare in psychology. This research tested variation in the replicability of 13 classic and contemporary effects across 36 independent samples totaling 6,344 participants. In the aggregate, 10 effects replicated consistently. One effect – imagined contact reducing prejudice – showed weak support for replicability. And two effects – flag priming influencing conservatism and currency priming influencing system justification – did not replicate. We compared whether the conditions such as lab versus online or US versus international sample predicted effect magnitudes. By and large they did not. The results of this small sample of effects suggest that replicability is more dependent on the effect itself than on the sample and setting used to investigate the effect.</abstract><remote-database-name>econtent.hogrefe.com (Atypon)</remote-database-name><urls><web-urls><url>https://econtent.hogrefe.com/doi/10.1027/1864-9335/a000178</url></web-urls></urls><access-date>2024-02-13 13:26:20</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Errington, Timothy M</author><author>Mathur, Maya</author><author>Soderberg, Courtney K</author><author>Denis, Alexandria</author><author>Perfito, Nicole</author><author>Iorns, Elizabeth</author><author>Nosek, Brian A</author></authors><secondary-authors><author>Pasqualini, Renata</author><author>Franco, Eduardo</author></secondary-authors></contributors><titles><title>Investigating the replicability of preclinical cancer biology</title><secondary-title>eLife</secondary-title></titles><periodical><full-title>eLife</full-title></periodical><pages>e71601</pages><volume>10</volume><keywords><keyword>reproducibility</keyword></keywords><dates><year>2021</year><pub-dates><date>2021-12-07</date></pub-dates></dates><isbn>2050-084X</isbn><electronic-resource-num>10.7554/eLife.71601</electronic-resource-num><abstract>Replicability is an important feature of scientific research, but aspects of contemporary research culture, such as an emphasis on novelty, can make replicability seem less important than it should be. The Reproducibility Project: Cancer Biology was set up to provide evidence about the replicability of preclinical research in cancer biology by repeating selected experiments from high-impact papers. A total of 50 experiments from 23 papers were repeated, generating data about the replicability of a total of 158 effects. Most of the original effects were positive effects (136), with the rest being null effects (22). A majority of the original effect sizes were reported as numerical values (117), with the rest being reported as representative images (41). We employed seven methods to assess replicability, and some of these methods were not suitable for all the effects in our sample. One method compared effect sizes: for positive effects, the median effect size in the replications was 85% smaller than the median effect size in the original experiments, and 92% of replication effect sizes were smaller than the original. The other methods were binary – the replication was either a success or a failure – and five of these methods could be used to assess both positive and null effects when effect sizes were reported as numerical values. For positive effects, 40% of replications (39/97) succeeded according to three or more of these five methods, and for null effects 80% of replications (12/15) were successful on this basis; combining positive and null effects, the success rate was 46% (51/112). A successful replication does not definitively confirm an original finding or its theoretical interpretation. Equally, a failure to replicate does not disconfirm a finding, but it does suggest that additional investigation is needed to establish its reliability.</abstract><remote-database-name>eLife</remote-database-name><urls><web-urls><url>https://doi.org/10.7554/eLife.71601</url></web-urls></urls><access-date>2024-02-13 12:54:52</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Milcu, Alexandru</author><author>Puga-Freitas, Ruben</author><author>Ellison, Aaron M.</author><author>Blouin, Manuel</author><author>Scheu, Stefan</author><author>Freschet, Grégoire T.</author><author>Rose, Laura</author><author>Barot, Sebastien</author><author>Cesarz, Simone</author><author>Eisenhauer, Nico</author><author>Girin, Thomas</author><author>Assandri, Davide</author><author>Bonkowski, Michael</author><author>Buchmann, Nina</author><author>Butenschoen, Olaf</author><author>Devidal, Sebastien</author><author>Gleixner, Gerd</author><author>Gessler, Arthur</author><author>Gigon, Agnès</author><author>Greiner, Anna</author><author>Grignani, Carlo</author><author>Hansart, Amandine</author><author>Kayler, Zachary</author><author>Lange, Markus</author><author>Lata, Jean-Christophe</author><author>Le Galliard, Jean-François</author><author>Lukac, Martin</author><author>Mannerheim, Neringa</author><author>Müller, Marina E. H.</author><author>Pando, Anne</author><author>Rotter, Paula</author><author>Scherer-Lorenzen, Michael</author><author>Seyhun, Rahme</author><author>Urban-Mead, Katherine</author><author>Weigelt, Alexandra</author><author>Zavattaro, Laura</author><author>Roy, Jacques</author></authors></contributors><titles><title>Genotypic variability enhances the reproducibility of an ecological study</title><secondary-title>Nature Ecology &amp; Evolution</secondary-title></titles><periodical><full-title>Nature Ecology &amp; Evolution</full-title><abbr-1>Nat Ecol Evol</abbr-1></periodical><pages>279-287</pages><volume>2</volume><number>2</number><issue>2</issue><dates><year>2018</year><pub-dates><date>2018-01-15</date></pub-dates></dates><isbn>2397-334X</isbn><electronic-resource-num>10.1038/s41559-017-0434-x</electronic-resource-num><remote-database-name>DOI.org (Crossref)</remote-database-name><language>en</language><urls><web-urls><url>https://www.nature.com/articles/s41559-017-0434-x</url></web-urls></urls><access-date>2024-02-13 13:33:04</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Protzko, John</author><author>Krosnick, Jon</author><author>Nelson, Leif</author><author>Nosek, Brian A.</author><author>Axt, Jordan</author><author>Berent, Matt</author><author>Buttrick, Nicholas</author><author>DeBell, Matthew</author><author>Ebersole, Charles R.</author><author>Lundmark, Sebastian</author><author>MacInnis, Bo</author><author>O’Donnell, Michael</author><author>Perfecto, Hannah</author><author>Pustejovsky, James E.</author><author>Roeder, Scott S.</author><author>Walleczek, Jan</author><author>Schooler, Jonathan W.</author></authors></contributors><titles><title>High replicability of newly discovered social-behavioural findings is achievable</title><secondary-title>Nature Human Behaviour</secondary-title></titles><periodical><full-title>Nature Human Behaviour</full-title><abbr-1>Nat Hum Behav</abbr-1></periodical><pages>1-9</pages><keywords><keyword>Human behaviour</keyword><keyword>Psychology</keyword></keywords><dates><year>2023</year><pub-dates><date>2023-11-09</date></pub-dates></dates><isbn>2397-3374</isbn><electronic-resource-num>10.1038/s41562-023-01749-9</electronic-resource-num><abstract>Failures to replicate evidence of new discoveries have forced scientists to ask whether this unreliability is due to suboptimal implementation of methods or whether presumptively optimal methods are not, in fact, optimal. This paper reports an investigation by four coordinated laboratories of the prospective replicability of 16 novel experimental findings using rigour-enhancing practices: confirmatory tests, large sample sizes, preregistration and methodological transparency. In contrast to past systematic replication efforts that reported replication rates averaging 50%, replication attempts here produced the expected effects with significance testing (P &lt; 0.05) in 86% of attempts, slightly exceeding the maximum expected replicability based on observed effect sizes and sample sizes. When one lab attempted to replicate an effect discovered by another lab, the effect size in the replications was 97% that in the original study. This high replication rate justifies confidence in rigour-enhancing methods to increase the replicability of new discoveries.</abstract><remote-database-name>www.nature.com</remote-database-name><language>en</language><urls><web-urls><url>https://www.nature.com/articles/s41562-023-01749-9</url></web-urls></urls><access-date>2024-02-13 13:30:40</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Camerer, Colin F.</author><author>Dreber, Anna</author><author>Holzmeister, Felix</author><author>Ho, Teck-Hua</author><author>Huber, Jürgen</author><author>Johannesson, Magnus</author><author>Kirchler, Michael</author><author>Nave, Gideon</author><author>Nosek, Brian A.</author><author>Pfeiffer, Thomas</author><author>Altmejd, Adam</author><author>Buttrick, Nick</author><author>Chan, Taizan</author><author>Chen, Yiling</author><author>Forsell, Eskil</author><author>Gampa, Anup</author><author>Heikensten, Emma</author><author>Hummer, Lily</author><author>Imai, Taisuke</author><author>Isaksson, Siri</author><author>Manfredi, Dylan</author><author>Rose, Julia</author><author>Wagenmakers, Eric-Jan</author><author>Wu, Hang</author></authors></contributors><titles><title>Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015</title><secondary-title>Nature Human Behaviour</secondary-title></titles><periodical><full-title>Nature Human Behaviour</full-title><abbr-1>Nat Hum Behav</abbr-1></periodical><pages>637-644</pages><volume>2</volume><number>9</number><issue>9</issue><keywords><keyword>Economics</keyword><keyword>Psychology</keyword></keywords><dates><year>2018</year><pub-dates><date>2018-09</date></pub-dates></dates><isbn>2397-3374</isbn><electronic-resource-num>10.1038/s41562-018-0399-z</electronic-resource-num><abstract>Being able to replicate scientific findings is crucial for scientific progress1–15. We replicate 21 systematically selected experimental studies in the social sciences published in Nature and Science between 2010 and 201516–36. The replications follow analysis plans reviewed by the original authors and pre-registered prior to the replications. The replications are high powered, with sample sizes on average about five times higher than in the original studies. We find a significant effect in the same direction as the original study for 13 (62%) studies, and the effect size of the replications is on average about 50% of the original effect size. Replicability varies between 12 (57%) and 14 (67%) studies for complementary replicability indicators. Consistent with these results, the estimated true-positive rate is 67% in a Bayesian analysis. The relative effect size of true positives is estimated to be 71%, suggesting that both false positives and inflated effect sizes of true positives contribute to imperfect reproducibility. Furthermore, we find that peer beliefs of replicability are strongly related to replicability, suggesting that the research community could predict which results would replicate and that failures to replicate were not the result of chance alone.</abstract><remote-database-name>www.nature.com</remote-database-name><language>en</language><urls><web-urls><url>https://www.nature.com/articles/s41562-018-0399-z</url></web-urls></urls><access-date>2024-02-13 13:18:43</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Camerer, Colin F.</author><author>Dreber, Anna</author><author>Forsell, Eskil</author><author>Ho, Teck-Hua</author><author>Huber, Jürgen</author><author>Johannesson, Magnus</author><author>Kirchler, Michael</author><author>Almenberg, Johan</author><author>Altmejd, Adam</author><author>Chan, Taizan</author><author>Heikensten, Emma</author><author>Holzmeister, Felix</author><author>Imai, Taisuke</author><author>Isaksson, Siri</author><author>Nave, Gideon</author><author>Pfeiffer, Thomas</author><author>Razen, Michael</author><author>Wu, Hang</author></authors></contributors><titles><title>Evaluating replicability of laboratory experiments in economics</title><secondary-title>Science</secondary-title></titles><periodical><full-title>Science</full-title></periodical><pages>1433-1436</pages><volume>351</volume><number>6280</number><issue>6280</issue><dates><year>2016</year><pub-dates><date>2016-03-25</date></pub-dates></dates><electronic-resource-num>10.1126/science.aaf0918</electronic-resource-num><abstract>The replicability of some scientific findings has recently been called into question. To contribute data about replicability in economics, we replicated 18 studies published in the American Economic Review and the Quarterly Journal of Economics between 2011 and 2014. All of these replications followed predefined analysis plans that were made publicly available beforehand, and they all have a statistical power of at least 90% to detect the original effect size at the 5% significance level. We found a significant effect in the same direction as in the original study for 11 replications (61%); on average, the replicated effect size is 66% of the original. The replicability rate varies between 67% and 78% for four additional replicability indicators, including a prediction market measure of peer beliefs.</abstract><remote-database-name>science.org (Atypon)</remote-database-name><urls><web-urls><url>https://www.science.org/doi/10.1126/science.aaf0918</url></web-urls></urls><access-date>2024-02-13 13:18:58</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Boehm, Udo</author><author>Annis, Jeffrey</author><author>Frank, Michael J.</author><author>Hawkins, Guy E.</author><author>Heathcote, Andrew</author><author>Kellen, David</author><author>Krypotos, Angelos-Miltiadis</author><author>Lerche, Veronika</author><author>Logan, Gordon D.</author><author>Palmeri, Thomas J.</author><author>van Ravenzwaaij, Don</author><author>Servant, Mathieu</author><author>Singmann, Henrik</author><author>Starns, Jeffrey J.</author><author>Voss, Andreas</author><author>Wiecki, Thomas V.</author><author>Matzke, Dora</author><author>Wagenmakers, Eric-Jan</author></authors></contributors><titles><title>Estimating across-trial variability parameters of the Diffusion Decision Model: Expert advice and recommendations</title><secondary-title>Journal of Mathematical Psychology</secondary-title><short-title>Estimating across-trial variability parameters of the Diffusion Decision Model</short-title></titles><periodical><full-title>Journal of Mathematical Psychology</full-title><abbr-1>Journal of Mathematical Psychology</abbr-1></periodical><pages>46-75</pages><volume>87</volume><keywords><keyword>Across-trial variability parameters</keyword><keyword>Diffusion Decision Model</keyword><keyword>Parameter estimation</keyword></keywords><dates><year>2018</year><pub-dates><date>2018-12-01</date></pub-dates></dates><isbn>0022-2496</isbn><electronic-resource-num>10.1016/j.jmp.2018.09.004</electronic-resource-num><abstract>For many years the Diffusion Decision Model (DDM) has successfully accounted for behavioral data from a wide range of domains. Important contributors to the DDM’s success are the across-trial variability parameters, which allow the model to account for the various shapes of response time distributions encountered in practice. However, several researchers have pointed out that estimating the variability parameters can be a challenging task. Moreover, the numerous fitting methods for the DDM each come with their own associated problems and solutions. This often leaves users in a difficult position. In this collaborative project we invited researchers from the DDM community to apply their various fitting methods to simulated data and provide advice and expert guidance on estimating the DDM’s across-trial variability parameters using these methods. Our study establishes a comprehensive reference resource and describes methods that can help to overcome the challenges associated with estimating the DDM’s across-trial variability parameters.</abstract><remote-database-name>ScienceDirect</remote-database-name><urls><web-urls><url>https://www.sciencedirect.com/science/article/pii/S002224961830021X</url></web-urls></urls><access-date>2024-02-13 15:27:26</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>OPEN SCIENCE COLLABORATION</author></authors></contributors><titles><title>Estimating the reproducibility of psychological science</title><secondary-title>Science</secondary-title></titles><periodical><full-title>Science</full-title></periodical><pages>aac4716</pages><volume>349</volume><number>6251</number><issue>6251</issue><dates><year>2015</year><pub-dates><date>2015-08-28</date></pub-dates></dates><electronic-resource-num>10.1126/science.aac4716</electronic-resource-num><abstract>Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.</abstract><remote-database-name>science.org (Atypon)</remote-database-name><urls><web-urls><url>https://www.science.org/doi/10.1126/science.aac4716</url></web-urls></urls><access-date>2024-02-13 12:54:24</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Cova, Florian</author><author>Strickland, Brent</author><author>Abatista, Angela</author><author>Allard, Aurélien</author><author>Andow, James</author><author>Attie, Mario</author><author>Beebe, James</author><author>Berniūnas, Renatas</author><author>Boudesseul, Jordane</author><author>Colombo, Matteo</author><author>Cushman, Fiery</author><author>Diaz, Rodrigo</author><author>N’Djaye Nikolai van Dongen, Noah</author><author>Dranseika, Vilius</author><author>Earp, Brian D.</author><author>Torres, Antonio Gaitán</author><author>Hannikainen, Ivar</author><author>Hernández-Conde, José V.</author><author>Hu, Wenjia</author><author>Jaquet, François</author><author>Khalifa, Kareem</author><author>Kim, Hanna</author><author>Kneer, Markus</author><author>Knobe, Joshua</author><author>Kurthy, Miklos</author><author>Lantian, Anthony</author><author>Liao, Shen-yi</author><author>Machery, Edouard</author><author>Moerenhout, Tania</author><author>Mott, Christian</author><author>Phelan, Mark</author><author>Phillips, Jonathan</author><author>Rambharose, Navin</author><author>Reuter, Kevin</author><author>Romero, Felipe</author><author>Sousa, Paulo</author><author>Sprenger, Jan</author><author>Thalabard, Emile</author><author>Tobia, Kevin</author><author>Viciana, Hugo</author><author>Wilkenfeld, Daniel</author><author>Zhou, Xiang</author></authors></contributors><titles><title>Estimating the Reproducibility of Experimental Philosophy</title><secondary-title>Review of Philosophy and Psychology</secondary-title></titles><periodical><full-title>Review of Philosophy and Psychology</full-title><abbr-1>Rev.Phil.Psych.</abbr-1></periodical><pages>9-44</pages><volume>12</volume><number>1</number><issue>1</issue><dates><year>2021</year><pub-dates><date>2021-03-01</date></pub-dates></dates><isbn>1878-5166</isbn><electronic-resource-num>10.1007/s13164-018-0400-9</electronic-resource-num><abstract>Responding to recent concerns about the reliability of the published literature in psychology and other disciplines, we formed the X-Phi Replicability Project (XRP) to estimate the reproducibility of experimental philosophy (osf.io/dvkpr). Drawing on a representative sample of 40 x-phi studies published between 2003 and 2015, we enlisted 20 research teams across 8 countries to conduct a high-quality replication of each study in order to compare the results to the original published findings. We found that x-phi studies – as represented in our sample – successfully replicated about 70% of the time. We discuss possible reasons for this relatively high replication rate in the field of experimental philosophy and offer suggestions for best research practices going forward.</abstract><remote-database-name>Springer Link</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1007/s13164-018-0400-9</url></web-urls></urls><access-date>2024-02-13 13:16:59</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Brauer, Jurgen</author></authors></contributors><titles><title>Data, Models, Coefficients: The Case of United States Military Expenditure</title><secondary-title>Conflict Management and Peace Science</secondary-title><short-title>Data, Models, Coefficients</short-title></titles><periodical><full-title>Conflict Management and Peace Science</full-title></periodical><pages>55-64</pages><volume>24</volume><number>1</number><issue>1</issue><dates><year>2007</year><pub-dates><date>2007-02-01</date></pub-dates></dates><isbn>0738-8942</isbn><electronic-resource-num>10.1080/07388940601102845</electronic-resource-num><abstract>This article is an exercise in economic methodology. It replicates two published models of the effect of military expenditure on the United States economy but, in order to study variations in the relevant estimated parameters, applies two different military expenditure data sets to the models (budget vs. National Income and Product Accounts [NIPA] data). In an extension, the article examines coefficient stability when the economically preferred NIPA data are applied across varying time-periods. Two major findings are that economic models should avoid the use of budget data and that even when the preferred NIPA data are used, estimated parameters are highly unstable across time.</abstract><remote-database-name>SAGE Journals</remote-database-name><language>en</language><urls><web-urls><url>https://doi.org/10.1080/07388940601102845</url></web-urls></urls><access-date>2024-02-13 13:38:27</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Wang, Shirley V.</author><author>Schneeweiss, Sebastian</author><author>RCT-DUPLICATE Initiative</author></authors></contributors><titles><title>Emulation of Randomized Clinical Trials With Nonrandomized Database Analyses: Results of 32 Clinical Trials</title><secondary-title>JAMA</secondary-title><short-title>Emulation of Randomized Clinical Trials With Nonrandomized Database Analyses</short-title></titles><periodical><full-title>JAMA</full-title><abbr-1>JAMA</abbr-1></periodical><pages>1376-1385</pages><volume>329</volume><number>16</number><issue>16</issue><dates><year>2023</year><pub-dates><date>2023-04-25</date></pub-dates></dates><isbn>0098-7484</isbn><electronic-resource-num>10.1001/jama.2023.4221</electronic-resource-num><abstract>Nonrandomized studies using insurance claims databases can be analyzed to produce real-world evidence on the effectiveness of medical products. Given the lack of baseline randomization and measurement issues, concerns exist about whether such studies produce unbiased treatment effect estimates.To emulate the design of 30 completed and 2 ongoing randomized clinical trials (RCTs) of medications with database studies using observational analogues of the RCT design parameters (population, intervention, comparator, outcome, time [PICOT]) and to quantify agreement in RCT-database study pairs.New-user cohort studies with propensity score matching using 3 US claims databases (Optum Clinformatics, MarketScan, and Medicare). Inclusion-exclusion criteria for each database study were prespecified to emulate the corresponding RCT. RCTs were explicitly selected based on feasibility, including power, key confounders, and end points more likely to be emulated with real-world data. All 32 protocols were registered on ClinicalTrials.gov before conducting analyses. Emulations were conducted from 2017 through 2022.Therapies for multiple clinical conditions were included.Database study emulations focused on the primary outcome of the corresponding RCT. Findings of database studies were compared with RCTs using predefined metrics, including Pearson correlation coefficients and binary metrics based on statistical significance agreement, estimate agreement, and standardized difference.In these highly selected RCTs, the overall observed agreement between the RCT and the database emulation results was a Pearson correlation of 0.82 (95% CI, 0.64-0.91), with 75% meeting statistical significance, 66% estimate agreement, and 75% standardized difference agreement. In a post hoc analysis limited to 16 RCTs with closer emulation of trial design and measurements, concordance was higher (Pearson r, 0.93; 95% CI, 0.79-0.97; 94% meeting statistical significance, 88% estimate agreement, 88% standardized difference agreement). Weaker concordance occurred among 16 RCTs for which close emulation of certain design elements that define the research question (PICOT) with data from insurance claims was not possible (Pearson r, 0.53; 95% CI, 0.00-0.83; 56% meeting statistical significance, 50% estimate agreement, 69% standardized difference agreement).Real-world evidence studies can reach similar conclusions as RCTs when design and measurements can be closely emulated, but this may be difficult to achieve. Concordance in results varied depending on the agreement metric. Emulation differences, chance, and residual confounding can contribute to divergence in results and are difficult to disentangle.</abstract><remote-database-name>Silverchair</remote-database-name><urls><web-urls><url>https://doi.org/10.1001/jama.2023.4221</url></web-urls></urls><access-date>2024-02-13 13:25:58</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Amini, Shahram M.</author><author>Parmeter, Christopher F.</author></authors></contributors><titles><title>Comparison of Model Averaging Techniques: Assessing Growth Determinants</title><secondary-title>Journal of Applied Econometrics</secondary-title><short-title>Comparison of Model Averaging Techniques</short-title></titles><periodical><full-title>Journal of Applied Econometrics</full-title></periodical><pages>870-876</pages><volume>27</volume><number>5</number><issue>5</issue><dates><year>2012</year><pub-dates><date>2012</date></pub-dates></dates><isbn>1099-1255</isbn><electronic-resource-num>10.1002/jae.2288</electronic-resource-num><abstract>This paper investigates the replicability of three important studies on growth theory uncertainty that employed Bayesian model averaging tools. We compare these results with estimates obtained using alternative, recently developed model averaging techniques. Overall, we successfully replicate all three studies, find that the sign and magnitude of these new estimates are reasonably close to those produced via traditional Bayesian methods and deploy a novel strategy to implement one of the new averaging estimators. Copyright © 2012 John Wiley &amp; Sons, Ltd.</abstract><remote-database-name>Wiley Online Library</remote-database-name><language>en</language><urls><web-urls><url>https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.2288</url></web-urls></urls><access-date>2024-02-13 13:37:59</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Hanousek, Jan</author><author>Hajkova, Dana</author><author>Filer, Randall K.</author></authors></contributors><titles><title>A rise by any other name? Sensitivity of growth regressions to data source</title><secondary-title>Journal of Macroeconomics</secondary-title><short-title>A rise by any other name?</short-title></titles><periodical><full-title>Journal of Macroeconomics</full-title><abbr-1>Journal of Macroeconomics</abbr-1></periodical><pages>1188-1206</pages><volume>30</volume><number>3</number><issue>3</issue><keywords><keyword>Growth</keyword><keyword>Measurement</keyword></keywords><dates><year>2008</year><pub-dates><date>2008-09-01</date></pub-dates></dates><isbn>0164-0704</isbn><electronic-resource-num>10.1016/j.jmacro.2007.08.015</electronic-resource-num><abstract>Measured rates of growth in real per capita income differ drastically depending on the data source. This phenomenon occurs largely because data sets differ in whether and how they adjust for changes in relative prices across countries. Replication of several recent studies of growth determinants shows that results are sensitive in important ways to the choice of data. Previous warnings against using data adjusted to increase cross-country comparability to study within-country patterns over time (growth rates) have been largely ignored at the cost of possibly contaminating the conclusions.</abstract><remote-database-name>ScienceDirect</remote-database-name><urls><web-urls><url>https://www.sciencedirect.com/science/article/pii/S016407040700122X</url></web-urls></urls><access-date>2024-02-13 13:36:59</access-date></record><record><database name="MyLibrary">MyLibrary</database><source-app name="Zotero">Zotero</source-app><ref-type name="Journal Article">17</ref-type><contributors><authors><author>Coles, Nicholas A.</author><author>March, David S.</author><author>Marmolejo-Ramos, Fernando</author><author>Larsen, Jeff T.</author><author>Arinze, Nwadiogo C.</author><author>Ndukaihe, Izuchukwu L. G.</author><author>Willis, Megan L.</author><author>Foroni, Francesco</author><author>Reggev, Niv</author><author>Mokady, Aviv</author><author>Forscher, Patrick S.</author><author>Hunter, John F.</author><author>Kaminski, Gwenaël</author><author>Yüvrük, Elif</author><author>Kapucu, Aycan</author><author>Nagy, Tamás</author><author>Hajdu, Nandor</author><author>Tejada, Julian</author><author>Freitag, Raquel M. K.</author><author>Zambrano, Danilo</author><author>Som, Bidisha</author><author>Aczel, Balazs</author><author>Barzykowski, Krystian</author><author>Adamus, Sylwia</author><author>Filip, Katarzyna</author><author>Yamada, Yuki</author><author>Ikeda, Ayumi</author><author>Eaves, Daniel L.</author><author>Levitan, Carmel A.</author><author>Leiweke, Sydney</author><author>Parzuchowski, Michal</author><author>Butcher, Natalie</author><author>Pfuhl, Gerit</author><author>Basnight-Brown, Dana M.</author><author>Hinojosa, José A.</author><author>Montoro, Pedro R.</author><author>Javela D, Lady G.</author><author>Vezirian, Kevin</author><author>IJzerman, Hans</author><author>Trujillo, Natalia</author><author>Pressman, Sarah D.</author><author>Gygax, Pascal M.</author><author>Özdoğru, Asil A.</author><author>Ruiz-Fernandez, Susana</author><author>Ellsworth, Phoebe C.</author><author>Gaertner, Lowell</author><author>Strack, Fritz</author><author>Marozzi, Marco</author><author>Liuzza, Marco Tullio</author></authors></contributors><titles><title>A multi-lab test of the facial feedback hypothesis by the Many Smiles Collaboration</title><secondary-title>Nature Human Behaviour</secondary-title></titles><periodical><full-title>Nature Human Behaviour</full-title><abbr-1>Nat Hum Behav</abbr-1></periodical><pages>1731-1742</pages><volume>6</volume><number>12</number><issue>12</issue><keywords><keyword>Human behaviour</keyword><keyword>Psychology</keyword></keywords><dates><year>2022</year><pub-dates><date>2022-12</date></pub-dates></dates><isbn>2397-3374</isbn><electronic-resource-num>10.1038/s41562-022-01458-9</electronic-resource-num><abstract>Following theories of emotional embodiment, the facial feedback hypothesis suggests that individuals’ subjective experiences of emotion are influenced by their facial expressions. However, evidence for this hypothesis has been mixed. We thus formed a global adversarial collaboration and carried out a preregistered, multicentre study designed to specify and test the conditions that should most reliably produce facial feedback effects. Data from n = 3,878 participants spanning 19 countries indicated that a facial mimicry and voluntary facial action task could both amplify and initiate feelings of happiness. However, evidence of facial feedback effects was less conclusive when facial feedback was manipulated unobtrusively via a pen-in-mouth task.</abstract><remote-database-name>www.nature.com</remote-database-name><language>en</language><urls><web-urls><url>https://www.nature.com/articles/s41562-022-01458-9</url></web-urls></urls><access-date>2024-02-13 13:31:08</access-date></record></records></xml>